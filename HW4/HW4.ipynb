{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "John Shamshoian\n",
    "\n",
    "Homework 4\n",
    "\n",
    "## Q1\n",
    "\n",
    "For a multivariate count vector $\\mathbf{x}=(x_1,\\ldots,x_d)$ with batch size $|\\mathbf{x}|=\\sum_{j=1}^d x_j$, show that the probability mass function for Dirichlet-multinomial distribution is\n",
    "$$\n",
    "    f(\\mathbf{x} \\mid \\alpha) \n",
    "\t= \\int_{\\Delta_d} \\binom{|\\mathbf{x}|}{\\mathbf{x}} \\prod_{j=1}^d p_j^{x_j} \\pi(\\mathbf{p}) \\, d \\mathbf{p}  \n",
    "    = \\binom{|\\mathbf{x}|}{\\mathbf{x}} \\frac{\\prod_{j=1}^d \\Gamma(\\alpha_j+x_j)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)} \\frac{\\Gamma(|\\alpha|)}{\\Gamma(|\\alpha|+|\\mathbf{x}|)}\n",
    "$$\n",
    "where $\\Delta_d$ is the unit simplex in $d$ dimensions and $|\\alpha| = \\sum_{j=1}^d \\alpha_j$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $\\mathbf{p} \\sim \\text{Dir}(\\mathbf{\\alpha})$, $\\mathbf{p}$ is a probability density. Therefore \n",
    "\n",
    "$$\n",
    "\\int_{\\Delta_d}\\pi(\\mathbf{p})\\,d\\mathbf{p} =  \\int_{\\Delta_d}\\frac{\\Gamma(|\\alpha|)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)}\\prod_{j=1}^d p_j^{\\alpha_j-1} \\, d\\mathbf{p} = 1\n",
    "$$\n",
    "\n",
    "Rearranging, I get $$\\int_{\\Delta_d}\\prod_{j=1}^d p_j^{\\alpha_j-1}\\,d\\mathbf{p} = \\frac{\\prod_{j=1}^d \\Gamma(\\alpha_j)}{\\Gamma(|\\alpha|)}$$\n",
    "\n",
    "If $\\mathbf{x} \\sim \\text{Multinomial}(\\mathbf{p})$ and $\\mathbf{p} \\sim \\text{Dir}(\\mathbf{\\alpha})$, then $p(\\mathbf{x}\\,|\\,\\mathbf{p},\\mathbf{\\alpha}) = p(\\mathbf{x}\\,|\\,\\mathbf{p})$. Using this fact, I have\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p(\\mathbf{x}, \\mathbf{p}\\,|\\,\\mathbf{\\alpha})&=\\frac{p(\\mathbf{x},\\mathbf{p},\\mathbf{\\alpha})}{p(\\mathbf{\\alpha})}\\cdot\\frac{p(\\mathbf{p},\\mathbf{\\alpha})}{p(\\mathbf{p},\\mathbf{\\alpha})}\\\\\\\\\n",
    "&= p(\\mathbf{x}\\,|\\,\\mathbf{p},\\mathbf{\\alpha})\\cdot p(\\mathbf{p}\\,|\\,\\mathbf{\\alpha})\\\\\\\\\n",
    "&= p(\\mathbf{x}\\,|\\,\\mathbf{p})\\cdot p(\\mathbf{p}\\,|\\,\\mathbf{\\alpha})\\\\\\\\\n",
    "&= \\binom{|\\mathbf{x}|}{\\mathbf{x}} \\prod_{j=1}^d p_j^{x_j} \\frac{\\Gamma(|\\alpha|)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)} \\prod_{j=1}^d p_j^{\\alpha_j-1}\\\\\\\\\n",
    "&= \\binom{|\\mathbf{x}|}{\\mathbf{x}} \\frac{\\Gamma(|\\alpha|)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)} \\prod_{j=1}^d p_j^{x_j + \\alpha_j-1}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "This implies \n",
    "$$\n",
    "\\begin{align}\n",
    "p(\\mathbf{x}\\,|\\,\\mathbf{\\alpha}) &= \\int_{\\Delta_d}p(\\mathbf{x},\\mathbf{p}\\,|\\,\\mathbf{\\alpha})\\,d\\mathbf{p}\\\\\\\\\n",
    "&= \\binom{|\\mathbf{x}|}{\\mathbf{x}} \\frac{\\Gamma(|\\alpha|)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)}\\int_{\\Delta_d}\\prod_{j=1}^d p_j^{x_j + \\alpha_j-1}\\,d\\mathbf{p}\\\\\\\\\n",
    "&= \\binom{|\\mathbf{x}|}{\\mathbf{x}} \\frac{\\Gamma(|\\alpha|)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)}\\frac{\\prod_{j=1}^d \\Gamma(x_j+\\alpha_j)}{\\Gamma(|\\mathbf{x}|+|\\alpha|)}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2\n",
    "\n",
    "The log-likelihood is\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L(\\alpha) &= \\log(p(\\mathbf{x}\\,|\\,\\alpha))\\\\\\\\\n",
    "&=\\log\\bigg[\\binom{|\\mathbf{x}|}{\\mathbf{x}} \\frac{\\Gamma(|\\alpha|)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)}\\frac{\\prod_{j=1}^d \\Gamma(x_j+\\alpha_j)}{\\Gamma(|\\mathbf{x}|+|\\alpha|)}\\bigg]\\\\\\\\\n",
    "&=\\log\\bigg[\\binom{|\\mathbf{x}|}{\\mathbf{x}}\\bigg] + \\log\\bigg[\\frac{\\prod_{j=1}^{d}\\Gamma(x_j+\\alpha_j}{\\prod_{j=1}^{d}\\Gamma(\\alpha_j)}\\bigg] + \\log\\bigg[\\frac{\\Gamma(|\\alpha|)}{\\Gamma(|\\mathbf{x}|+|\\alpha|)}\\bigg]\\\\\\\\\n",
    "&=\\log\\bigg[\\binom{|\\mathbf{x}|}{\\mathbf{x}}\\bigg] + \\sum_{j=1}^{d}\\bigg[\\log\\Gamma(x_j+\\alpha_j)-\\log\\Gamma(\\alpha_j)\\bigg] - \\bigg[\\log\\Gamma(|x|+|\\alpha|)-\\log\\Gamma(|\\alpha|)\\bigg]\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "For indpendent $\\mathbf{x_1}, \\mathbf{x_2},\\ldots,\\mathbf{x_n}$ the log-likelihood becomes \n",
    "\n",
    "$$\\sum_{i=1}^{n}\\log\\bigg[\\binom{|\\mathbf{x_i}|}{\\mathbf{x_i}}\\bigg] + \\sum_{i=1}^{n}\\sum_{j=1}^{d}\\bigg[\\log\\Gamma(x_{ij}+\\alpha_j)-\\log\\Gamma(\\alpha_j)\\bigg] - \\sum_{i=1}^{n}\\bigg[\\log\\Gamma(|\\mathbf{x_i}|+|\\alpha|)-\\log\\Gamma(|\\alpha|)\\bigg]$$\n",
    "\n",
    "\n",
    "The log-likelihood is not concave. I will show the hessian matrix is not always negative definite.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{d^2}{d\\alpha_1^2}L(\\alpha\\,|\\,\\mathbf{x}) = \\psi_1(x_1+\\alpha_1)-\\psi_1(\\alpha_1)-\\psi_1(x_1+x_2+\\alpha_1+\\alpha_2)+\\psi_1(\\alpha_1+\\alpha_2)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Where $\\psi_1$ is the trigamma function.\n",
    "\n",
    "Let $n=1, \\alpha_1 = 10, \\alpha_2=1,x_1=1,x_2=2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021126067017675415"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "α1 = 10\n",
    "α2 = 1\n",
    "x1 = 1\n",
    "x2 = 2\n",
    "trigamma(x1 + α1) - trigamma(α1) \n",
    "- trigamma(x1 + x2 + α1 + α2) + trigamma(α1 + α2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $\\displaystyle\\frac{d^2}{d\\alpha_1^2}L(\\alpha\\,|\\,\\mathbf{x}) > 0$, the diagonal of the hessian is positive. Therefore the hessian is not always negative definite. The log-likelihood is not concave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dirmult_logpdf"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    dirmult_logpdf(x::Vector, α::Vector)\n",
    "    \n",
    "Compute the log-pdf of Dirichlet-multinomial distribution with parameter `α` \n",
    "at data point `x`.\n",
    "\"\"\"\n",
    "function dirmult_logpdf(x::Vector, α::Vector)\n",
    "    s = 0\n",
    "    result = 0\n",
    "    for i in 1:length(x)\n",
    "        #s += x[i]\n",
    "        #result += sum(log(1:s)) - sum(log(1:x[i])) - sum(log(1:(s - x[i])))\n",
    "        result += - lfact(x[i])\n",
    "    end\n",
    "\n",
    "    storage = 0\n",
    "    for i in 1:length(x)\n",
    "        storage += lgamma(x[i] + α[i]) - lgamma(α[i])\n",
    "    end\n",
    "    #print(lgamma(α[1]))\n",
    "    return result + storage - lgamma(sum(α) + sum(x)) + lgamma(sum(α)) + lfact(sum(x))\n",
    "end\n",
    "\n",
    "function dirmult_logpdf!(r::Vector, X::Matrix, α::Vector)\n",
    "    for j in 1:size(X, 2)\n",
    "        r[j] = dirmult_logpdf(X[:, j], α)\n",
    "    end\n",
    "    return r\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    dirmult_logpdf(X, α)\n",
    "    \n",
    "Compute the log-pdf of Dirichlet-multinomial distribution with parameter `α` \n",
    "at each data point in `X`. Each column of `X` is one data point.\n",
    "\"\"\"\n",
    "function dirmult_logpdf(X::Matrix, α::Vector)\n",
    "    r = zeros(size(X, 2))\n",
    "    dirmult_logpdf!(r, X, α)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optdigits = readcsv(\"E:/Classes/BiostatisticsM280/Submissions/biostat-m280-JohnShamshoian/HW4/optdigits.tra\")\n",
    "training = Int64.(optdigits[:, 1:64]);\n",
    "digits = Int64.(optdigits[:, 65]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3823-element Array{Float64,1}:\n",
       " -165.188\n",
       " -176.23 \n",
       " -167.774\n",
       " -165.564\n",
       " -157.79 \n",
       " -176.071\n",
       " -158.423\n",
       " -159.258\n",
       " -174.302\n",
       " -178.407\n",
       " -171.294\n",
       " -169.383\n",
       " -175.753\n",
       "    ⋮    \n",
       " -160.49 \n",
       " -158.633\n",
       " -156.935\n",
       " -171.975\n",
       " -177.638\n",
       " -169.735\n",
       " -158.423\n",
       " -159.465\n",
       " -159.877\n",
       " -169.735\n",
       " -173.149\n",
       " -155.411"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirmult_logpdf(training', [1; ones(Int64, 63)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5\n",
    "\n",
    "The score function is $\\nabla L(\\alpha) = \\displaystyle\\frac{d}{d\\mathbf{\\alpha}}L(\\alpha)$, where \n",
    "\n",
    "$$\\displaystyle\\frac{d}{d\\alpha_j}L(\\alpha)=\\sum_{i=1}^{n}\\bigg[\\psi(x_{ij} + \\alpha_j)-\\psi(\\alpha_j)\\bigg]-\\sum_{i=1}^{n}\\bigg[\\psi(|\\mathbf{x_i}| + |\\alpha|)-\\psi(|\\alpha|)\\bigg]$$\n",
    "\n",
    "$\\psi$ is the digamma function.\n",
    "\n",
    "The observed information is $-d^{2}L(\\alpha)$, where\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\big[-d^{2}L(\\alpha))\\big]_{kj} &= -\\frac{d}{d\\alpha_k\\alpha_j}L(\\alpha)\\\\\\\\\n",
    "&=\\begin{cases}\n",
    "  \\displaystyle\\sum_{i=1}^{n}\\bigg[\\psi_{1}(|\\mathbf{x_i}|+|\\alpha|) - \\psi_1(|\\alpha|)\\bigg]-\\displaystyle\\sum_{i=1}^{n}\\bigg[\\psi_{1}(x_{ij}+\\alpha_j)-\\psi_1(\\alpha_j)\\bigg] & \\text{if }k = j\\\\\\\\\n",
    " \\displaystyle\\sum_{i=1}^{n}\\bigg[\\psi_{1}(|\\mathbf{x_i}|+|\\alpha|) - \\psi_1(|\\alpha|)\\bigg] & \\text{if }k\\neq j\n",
    "\\end{cases}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "To derive the expected information matrix $\\mathbb{E}[-d^{2}L(\\alpha)]$ I will use the alternate form of the log-likelihood from homework 5.\n",
    "\n",
    "$$\n",
    "L(\\alpha) = \\sum_{i=1}^{n}\\ln\\binom{|\\mathbf{x_i}|}{\\mathbf{x_i}} + \\sum_{i=1}^{n}\\sum_{j=1}^{d}\\sum_{k=0}^{x_{ij}-1}\\ln(\\alpha_j+k)-\\sum_{i=1}^{n}\\sum_{k=0}^{|\\mathbf{x_i}|-1}\\ln(|\\alpha|+k)\n",
    "$$\n",
    "\n",
    "For $k\\neq j$,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}[-d^{2}L(\\alpha)]_{kj} &=- \\sum_{i=1}^{n}\\sum_{x_{i1},\\ldots,x_{id}}^{|\\mathbf{x_i}|}\\sum_{k=0}^{|\\mathbf{x_i}|-1}\\frac{1}{(|\\alpha|+k)^2}p(\\mathbf{x_i})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "And for $k=j$,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}[-d^{2}L(\\alpha)]_{kj}=\\sum_{i=1}^{n}\\sum_{x_{i1}\\ldots,x_{id}}^{|\\mathbf{x_i}|}\\sum_{k=0}^{x_{ij}-1}\\frac{1}{(\\alpha_{j}+k)^2}p(\\mathbf{x_i})-\\sum_{i=1}^{n}\\sum_{x_{i1}\\ldots,x_{id}}^{|\\mathbf{x_i}|}\\sum_{k=0}^{|\\mathbf{x_i}|-1}\\frac{1}{(|\\alpha|+k)^2}p(\\mathbf{x_i})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Fisher scoring is inefficient because the triple summation would take a while to compute for each iteration of the newton-raphson algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6\n",
    "\n",
    "The observed information matrix has the structure $D+11'(-p)$, where $D$ is a $d\\times d$ diagonal matrix with positive entries, $p$ is a positive constant, and $1$ is a $d\\times 1$ vector of ones.\n",
    "\n",
    "$D+11'(-p)$ is positive definite if and only if $(D+11'(-p))^{-1} = D^{-1} - \\displaystyle\\frac{D^{-1}11'(-p)D^{-1}}{1+(-p)1'D^{-1}1} = D^{-1}+\\displaystyle\\frac{D^{-1}11'(p)D^{-1}}{1-p1'D^{-1}1}$ is positive definite.\n",
    "\n",
    "From this expression I see that if $1-p1'D^{-1}1 > 0$, then $(D+11'(-p))^{-1}$ is positive definite.\n",
    "\n",
    "In other words, the observed information matrix is positive definite if $p1'D^{-1}1<1$. If $p1'D^{-1}1\\nless 1$, set $p^{*} = \\displaystyle\\frac{.95}{1'D^{-1}1}$. Then replace the observed information matrix with $D+11'(-p^{*})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7\n",
    "\n",
    "In the context of Q1, the multinomial probabilities $\\mathbf{p} = (p_1,\\ldots,p_{d-1})$ are random variables with $\\mathbb{E}[p_i] = \\displaystyle\\frac{\\alpha_i}{|\\alpha|}$ and $Var(p_i) = \\displaystyle\\frac{\\alpha_i(|\\alpha| - \\alpha_i)}{|\\alpha|^2(|\\alpha| +1)}$.\n",
    "\n",
    "Also $\\mathbb{E}(x_i) = \\mathbf{x}\\displaystyle\\frac{\\alpha_i}{|\\alpha|}$ and $Var(X_i) = |\\mathbf{x}|\\displaystyle\\frac{\\alpha_i}{|\\alpha|}\\bigg(1-\\frac{\\alpha_i}{|\\alpha|}\\bigg)\\bigg(\\frac{|\\mathbf{x}|+|\\alpha|}{1+|\\alpha|}\\bigg) = |\\mathbf{x}|\\,\\mathbb{E}[p_i](1-\\mathbb{E}[p_i])\\bigg(\\frac{|\\mathbf{x}|+|\\alpha|}{1+|\\alpha|}\\bigg)$\n",
    "\n",
    "Another result is $Cov(X_i,X_j) = -\\displaystyle\\frac{|\\mathbf{x}|\\alpha_i\\alpha_j(|\\mathbf{x}| + |\\alpha|)}{|\\alpha|^2(1+|\\alpha|)} = -\\mathbb{E}[p_i]\\mathbb{E}[p_j]\\bigg(\\frac{|\\mathbf{x}|+|\\alpha|}{1+|\\alpha|}\\bigg)$\n",
    "\n",
    "Comparing with the multinomial distribution: If $(x_1,\\ldots,x_{d-1}) \\sim M(p_1,\\ldots,p_{d-1})$, $Var(X_i) = |\\mathbf{x}|p_i(1-p_i)$ and $Cov(x_i,x_j) = -|\\mathbf{x}|p_ip_j$\n",
    "\n",
    "It follows that $\\Sigma_{DM} = \\displaystyle\\bigg[\\frac{|\\mathbf{x}+|\\alpha|}{1+|\\alpha|}\\bigg]\\Sigma_M = C\\Sigma_M$, where $\\Sigma_{DM}$ is the covariance matrix of $\\mathbf{x}$ treating $\\mathbf{x}$ as dirichlet multinomial and $\\Sigma_M$ is the sample covariance matrix of $\\mathbf{x}$ treating $\\mathbf{x}$ as multinomial.\n",
    "\n",
    "So, $p_j$ can be estimated by $\\displaystyle\\frac{\\sum_{i=1}^{n}x_{ij}}{\\sum_{i=1}^{n}|\\mathbf{x_i}|}$ and $\\Sigma_{DM}$ can be estimated by $\\displaystyle\\frac{1}{n-1}\\sum_{i=1}^{N}(\\mathbf{x}_i-\\overline{\\mathbf{x}})(\\mathbf{x}_i-\\overline{\\mathbf{x}})^{T}$\n",
    "\n",
    "Solving for $C$, $\\hat{C} = \\displaystyle\\bigg(\\frac{|\\hat{\\Sigma}_{DM}|}{|\\hat{\\Sigma}_{M}|}\\bigg)^{1/(k-1)}$\n",
    "\n",
    "Since $\\mathbb{E}(x_i) = \\mathbf{x_i}\\displaystyle\\frac{\\alpha_i}{|\\alpha|}$, we have $\\mathbb{E}[|\\mathbf{\\overline{x}}_i|] = \\displaystyle\\frac{\\alpha_1}{|\\alpha|}\\sum_{i=1}^{n}|\\mathbf{x}_i|/n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    dirmult_newton(X)\n",
    "\n",
    "Find the MLE of Dirichlet-multinomial distribution using Newton's method.\n",
    "\n",
    "# Argument\n",
    "* `X`: an `n`-by-`d` matrix of counts; each column is one data point.\n",
    "\n",
    "# Optional argument  \n",
    "* `alpha0`: a `d` vector of starting point (optional). \n",
    "* `maxiters`: the maximum allowable Newton iterations (default 100). \n",
    "* `tolfun`: the tolerance for  relative change in objective values (default 1e-6). \n",
    "\n",
    "# Output\n",
    "* `maximum`: the log-likelihood at MLE.   \n",
    "* `estimate`: the MLE. \n",
    "* `gradient`: the gradient at MLE. \n",
    "* `hessian`: the Hessian at MLE. \n",
    "* `se`: a `d` vector of standard errors. \n",
    "* `iterations`: the number of iterations performed.\n",
    "\"\"\"\n",
    "function dirmult_newton(X::Matrix; α0::Vector = nothing, \n",
    "            maxiters::Int = 100, tolfun::Float64 = 1e-6)\n",
    "    \n",
    "    X = X[:, findnz(sum(X,1))[2]]\n",
    "    p = 0\n",
    "    n, m = size(X)\n",
    "    # set default starting point from Q7\n",
    "    α0 = ones(size(X)[2])\n",
    "    gradient = zeros(m)\n",
    "    D = Diagonal(zeros(m))\n",
    "    H = Array(Float64, m, m)\n",
    "    # Newton loop\n",
    "    for iter in 1:maxiters\n",
    "        for i in 1:m\n",
    "            for j in 1:n\n",
    "                gradient[i] = gradient[i] + digamma(X[j,i] + α0[i]) - digamma(α0[i]) - digamma(sum(X[j, :]) + sum(α0)) + digamma(sum(α0))\n",
    "            end\n",
    "        end\n",
    "        # evaluate gradient (score)\n",
    "        \n",
    "        # approximated observed information matrix\n",
    "        for j in 1:n\n",
    "            p = p + trigamma(sum(X[j, :]) + sum(α0)) - trigamma(sum(α0))\n",
    "        end\n",
    "        \n",
    "        p = -p\n",
    "                \n",
    "        for i = 1:m\n",
    "            for j in 1:n   \n",
    "                D[i,i] = D[i,i] + trigamma(α0[i]) - trigamma(α0[i] + X[j,i]) \n",
    "            end\n",
    "        end\n",
    "        \n",
    "        if (1 - p * dot(ones(m), inv(D) * ones(m))) <= 0\n",
    "            p = .95 * 1 / dot(ones(m), inv(D) * ones(m))\n",
    "            print(\"hi\")\n",
    "        end\n",
    "        \n",
    "        H = D + ones(m) * ones(m)' * (-p)\n",
    "        \n",
    "        \n",
    "        # compute Newton's direction\n",
    "        \n",
    "        α0 = α0 + inv(H) * gradient\n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "        # line search loop\n",
    "        for lsiter in 1:10\n",
    "            # step halving\n",
    "        end\n",
    "        \n",
    "        # check convergence criterion\n",
    "        if abs(logl - loglold) < tolfun * (abs(loglold) + 1)\n",
    "            break;\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # compute logl, gradient, Hessian from final iterate\n",
    "    \n",
    "    # output\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3823,64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64,3823)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m, n = size(training')\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52×52 Array{Float64,2}:\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  …  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  …  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  …  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " ⋮                        ⋮              ⋱  ⋮                        ⋮       \n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  …  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  …  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  …  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0"
      ]
     },
     "execution_count": 775,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    digitk = training[digits .== 2, :]\n",
    "X = digitk[:, findnz(sum(digitk,1))[2]]\n",
    "#X = training[:, findnz(sum(training,1))[2]]\n",
    "    #X = [1 2 3; 2 2 4; 1 3 5; 3 1 4]\n",
    "    #X = [collect(1:10) collect(5:14) collect(10:19)]\n",
    "    c = 0\n",
    "    n, m = size(X)\n",
    "    # set default starting point from Q7\n",
    "    α0 = ones(size(X)[2])\n",
    "    gradient = zeros(m)\n",
    "    D = Diagonal(zeros(m))\n",
    "    H = Array(Float64, m, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "hi1\n",
      "hi2\n",
      "hi3\n",
      "hi4\n",
      "hi5\n",
      "hi6\n",
      "hi7\n",
      "hi8\n",
      "hi9\n",
      "hi10\n",
      "hi11\n",
      "hi12\n",
      "hi13\n",
      "hi14\n",
      "hi15\n",
      "hi16\n",
      "hi17\n",
      "hi18\n",
      "hi19\n",
      "hi20\n",
      "hi21\n",
      "hi22\n",
      "hi23\n",
      "hi24\n",
      "hi25\n",
      "hi26\n",
      "hiconverged"
     ]
    }
   ],
   "source": [
    "loglold = sum(dirmult_logpdf(X',α0))\n",
    "logl = loglold\n",
    "counter = 0\n",
    "tolfun = 1e-6\n",
    "stepsize = 1\n",
    "αtemp = zeros(m)\n",
    "for iter in 1:100\n",
    "    loglold = logl\n",
    "    gradient = zeros(m)\n",
    "    D = Diagonal(zeros(m))\n",
    "    H = Array(Float64, m, m)\n",
    "        for j in 1:n\n",
    "            for i in 1:m\n",
    "                gradient[i] = gradient[i] + digamma(X[j,i] + α0[i]) - digamma(α0[i]) - digamma(sum(X[j, :]) + sum(α0)) + digamma(sum(α0))\n",
    "            end\n",
    "        end\n",
    "        # evaluate gradient (score)\n",
    "        \n",
    "        # approximated observed information matrix\n",
    "        for j in 1:n\n",
    "            c = c + trigamma(sum(X[j, :]) + sum(α0))\n",
    "        end\n",
    "        \n",
    "        c = c - n * trigamma(sum(α0))\n",
    "                \n",
    "        for i = 1:m\n",
    "            for j in 1:n   \n",
    "                D[i,i] = D[i,i] - trigamma(α0[i] + X[j,i]) \n",
    "            end\n",
    "            D[i, i] = D[i, i] + n * trigamma(α0[i]) \n",
    "        end\n",
    "        \n",
    "        if (1 + c * dot(ones(m), inv(D) * ones(m))) <= 0\n",
    "            c = -.95 * 1 / dot(ones(m), inv(D) * ones(m))\n",
    "            print(counter,\"\\n\")\n",
    "        counter = counter + 1\n",
    "        end\n",
    "        H = D + ones(m) * ones(m)' * c\n",
    "        \n",
    "        # line search loop\n",
    "        for lsiter in 1:10\n",
    "            s = (2.0)^(- 2 * lsiter + 2)\n",
    "            αtemp = α0 + inv(H) * gradient * s\n",
    "            logltemp = sum(dirmult_logpdf(X',αtemp))\n",
    "            if (logltemp > logl ) & (minimum(αtemp) > 0)\n",
    "            print(\"hi\")\n",
    "                stepsize = s\n",
    "                break;\n",
    "            end\n",
    "        end\n",
    "    \n",
    "        # compute Newton's direction\n",
    "        \n",
    "        α0 = α0 + inv(H) * gradient * stepsize\n",
    "        logl = sum(dirmult_logpdf(X',α0))\n",
    "        if abs(logl - loglold) < (tolfun * (abs(loglold) + 1))\n",
    "            print(\"converged\")\n",
    "            break;\n",
    "        end\n",
    "\n",
    "end\n",
    "#print(α0)\n",
    "#print(sum(dirmult_logpdf(X', α0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015716295701320743"
      ]
     },
     "execution_count": 777,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-54546.20542323654"
      ]
     },
     "execution_count": 755,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dirmult_logpdf(X',α0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000244140625"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 1\n",
    "        for lsiter in 1:20\n",
    "            s = (2.0)^(- lsiter - 1)\n",
    "            αtemp = α0 + inv(H) * gradient * s\n",
    "            logltemp = sum(dirmult_logpdf(X',αtemp))\n",
    "            if (logltemp > (logl + s * dot(gradient, inv(H) * gradient))) & (minimum(αtemp) > 0)\n",
    "                stepsize = s\n",
    "                break;\n",
    "            end\n",
    "        end\n",
    "\n",
    "αtemp\n",
    "    stepsize\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-51735.148891419056"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dirmult_logpdf(X', α0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62×62 Diagonal{Float64}:\n",
       " 0.00145156   ⋅            ⋅           …   ⋅            ⋅        \n",
       "  ⋅          0.000231805   ⋅               ⋅            ⋅        \n",
       "  ⋅           ⋅           0.000174492      ⋅            ⋅        \n",
       "  ⋅           ⋅            ⋅               ⋅            ⋅        \n",
       "  ⋅           ⋅            ⋅               ⋅            ⋅        \n",
       "  ⋅           ⋅            ⋅           …   ⋅            ⋅        \n",
       "  ⋅           ⋅            ⋅               ⋅            ⋅        \n",
       "  ⋅           ⋅            ⋅               ⋅            ⋅        \n",
       "  ⋅           ⋅            ⋅               ⋅            ⋅        \n",
       "  ⋅           ⋅            ⋅               ⋅            ⋅        \n",
       "  ⋅           ⋅            ⋅           …   ⋅            ⋅        \n",
       "  ⋅           ⋅            ⋅               ⋅            ⋅        \n",
       "  ⋅           ⋅            ⋅               ⋅            ⋅        \n",
       " ⋮                                     ⋱  ⋮                      \n",
       "  ⋅           ⋅            ⋅           …   ⋅            ⋅        \n",
       "  ⋅           ⋅            ⋅               ⋅            ⋅        \n",
       "  ⋅           ⋅            ⋅               ⋅            ⋅        \n",
       "  ⋅           ⋅            ⋅               ⋅            ⋅        \n",
       "  ⋅           ⋅            ⋅               ⋅            ⋅        \n",
       "  ⋅           ⋅            ⋅           …   ⋅            ⋅        \n",
       "  ⋅           ⋅            ⋅               ⋅            ⋅        \n",
       "  ⋅           ⋅            ⋅               ⋅            ⋅        \n",
       "  ⋅           ⋅            ⋅               ⋅            ⋅        \n",
       "  ⋅           ⋅            ⋅               ⋅            ⋅        \n",
       "  ⋅           ⋅            ⋅           …  0.000559595   ⋅        \n",
       "  ⋅           ⋅            ⋅               ⋅           0.00378724"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = Diagonal(zeros(m))\n",
    "for i = 1:m\n",
    "            for j in 1:n   \n",
    "                D[i,i] = D[i,i] + trigamma(α0[i]) - trigamma(α0[i] + X[j,i]) \n",
    "            end\n",
    "        end\n",
    "inv(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Float64,1}:\n",
       " 106.053"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-(p)*ones(62)'*inv(D)ones(62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(X[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×3 Array{Int64,2}:\n",
       " 1  2  3\n",
       " 2  2  4\n",
       " 1  3  5\n",
       " 3  1  4"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62×62 Array{Float64,2}:\n",
       "   2.71456e-315  2.122e-314    …  NaN             NaN           \n",
       "   2.71457e-315  0.0                0.0             2.45057e-321\n",
       "   2.122e-314    0.0              NaN             NaN           \n",
       "   2.71456e-315  0.0                1.92349e-315    1.9235e-315 \n",
       "   2.122e-314    5.78375e-316       2.48138e-315  NaN           \n",
       "   1.9235e-315   0.0           …    6.37345e-322    2.46045e-321\n",
       " NaN             2.71456e-315     NaN             NaN           \n",
       "   1.92355e-315  0.0                2.4308e-321     2.77171e-321\n",
       " NaN             2.71456e-315     NaN             NaN           \n",
       "   2.71456e-315  2.71456e-315       2.72724e-321  NaN           \n",
       "   2.71456e-315  2.71456e-315  …    2.48138e-315  NaN           \n",
       "   2.71456e-315  2.71457e-315       9.43665e-322    5.77625e-316\n",
       " NaN             2.122e-314       NaN             NaN           \n",
       "   ⋮                           ⋱    ⋮                           \n",
       " NaN             2.122e-314    …  NaN             NaN           \n",
       "   5.77768e-316  2.71457e-315       5.77625e-316    3.56221e-321\n",
       " NaN             2.122e-314       NaN             NaN           \n",
       " NaN             2.71457e-315       1.92355e-315    1.27963e-321\n",
       " NaN             2.122e-314       NaN             NaN           \n",
       "   3.27071e-321  2.71457e-315  …    1.92391e-315    2.35669e-321\n",
       "   4.94066e-324  2.71457e-315     NaN             NaN           \n",
       "   2.122e-314    2.71457e-315       3.78948e-321    5.77763e-316\n",
       "   4.94066e-324  2.71456e-315     NaN             NaN           \n",
       "   0.0           2.122e-314         5.77618e-316    4.16497e-321\n",
       " NaN             2.7146e-315   …  NaN             NaN           \n",
       "   4.24399e-314  2.122e-314         5.77625e-316  NaN           "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H = Array(Float64, m, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62-element Array{Float64,1}:\n",
       "    1.28477\n",
       "    3.82693\n",
       "    4.40066\n",
       "    5.725  \n",
       "   10.5857 \n",
       "   11.7259 \n",
       "   36.9622 \n",
       "   49.3614 \n",
       "   53.4904 \n",
       "   84.7534 \n",
       "  152.038  \n",
       "  186.813  \n",
       "  255.564  \n",
       "    ⋮      \n",
       " 4930.06   \n",
       " 4950.58   \n",
       " 5029.5    \n",
       " 5322.65   \n",
       " 5409.45   \n",
       " 5470.18   \n",
       " 5474.86   \n",
       " 5611.87   \n",
       " 5666.37   \n",
       " 5689.03   \n",
       " 5731.41   \n",
       " 5855.46   "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#H = D + ones(m) * ones(m)' * p\n",
    "v=.95*1.0/dot(ones(m), inv(D)*ones(m))\n",
    "#eig(D+ones(m)*ones(m)'*v)\n",
    "#size(D)\n",
    "eig(D+ones(m)*ones(m)'*v)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.1",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
