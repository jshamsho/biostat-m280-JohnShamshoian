{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "John Shamshoian\n",
    "\n",
<<<<<<< HEAD
    "Homework 4\n",
    "\n",
    "## Q1\n",
    "\n",
    "For a multivariate count vector $\\mathbf{x}=(x_1,\\ldots,x_d)$ with batch size $|\\mathbf{x}|=\\sum_{j=1}^d x_j$, show that the probability mass function for Dirichlet-multinomial distribution is\n",
    "$$\n",
    "    f(\\mathbf{x} \\mid \\alpha) \n",
    "\t= \\int_{\\Delta_d} \\binom{|\\mathbf{x}|}{\\mathbf{x}} \\prod_{j=1}^d p_j^{x_j} \\pi(\\mathbf{p}) \\, d \\mathbf{p}  \n",
    "    = \\binom{|\\mathbf{x}|}{\\mathbf{x}} \\frac{\\prod_{j=1}^d \\Gamma(\\alpha_j+x_j)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)} \\frac{\\Gamma(|\\alpha|)}{\\Gamma(|\\alpha|+|\\mathbf{x}|)}\n",
    "$$\n",
    "where $\\Delta_d$ is the unit simplex in $d$ dimensions and $|\\alpha| = \\sum_{j=1}^d \\alpha_j$.\n"
=======
    "Homework 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "using WoodburyMatrices\n",
    "using Distributions"
>>>>>>> 02a17ab1249aa599c4159256cdb2ae8a0bbb95ac
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
=======
    "## Q1\n",
    "\n",
>>>>>>> 02a17ab1249aa599c4159256cdb2ae8a0bbb95ac
    "If $\\mathbf{p} \\sim \\text{Dir}(\\mathbf{\\alpha})$, $\\mathbf{p}$ is a probability density. Therefore \n",
    "\n",
    "$$\n",
    "\\int_{\\Delta_d}\\pi(\\mathbf{p})\\,d\\mathbf{p} =  \\int_{\\Delta_d}\\frac{\\Gamma(|\\alpha|)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)}\\prod_{j=1}^d p_j^{\\alpha_j-1} \\, d\\mathbf{p} = 1\n",
    "$$\n",
    "\n",
    "Rearranging, I get $$\\int_{\\Delta_d}\\prod_{j=1}^d p_j^{\\alpha_j-1}\\,d\\mathbf{p} = \\frac{\\prod_{j=1}^d \\Gamma(\\alpha_j)}{\\Gamma(|\\alpha|)}$$\n",
    "\n",
    "If $\\mathbf{x} \\sim \\text{Multinomial}(\\mathbf{p})$ and $\\mathbf{p} \\sim \\text{Dir}(\\mathbf{\\alpha})$, then $p(\\mathbf{x}\\,|\\,\\mathbf{p},\\mathbf{\\alpha}) = p(\\mathbf{x}\\,|\\,\\mathbf{p})$. Using this fact, I have\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p(\\mathbf{x}, \\mathbf{p}\\,|\\,\\mathbf{\\alpha})&=\\frac{p(\\mathbf{x},\\mathbf{p},\\mathbf{\\alpha})}{p(\\mathbf{\\alpha})}\\cdot\\frac{p(\\mathbf{p},\\mathbf{\\alpha})}{p(\\mathbf{p},\\mathbf{\\alpha})}\\\\\\\\\n",
    "&= p(\\mathbf{x}\\,|\\,\\mathbf{p},\\mathbf{\\alpha})\\cdot p(\\mathbf{p}\\,|\\,\\mathbf{\\alpha})\\\\\\\\\n",
    "&= p(\\mathbf{x}\\,|\\,\\mathbf{p})\\cdot p(\\mathbf{p}\\,|\\,\\mathbf{\\alpha})\\\\\\\\\n",
    "&= \\binom{|\\mathbf{x}|}{\\mathbf{x}} \\prod_{j=1}^d p_j^{x_j} \\frac{\\Gamma(|\\alpha|)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)} \\prod_{j=1}^d p_j^{\\alpha_j-1}\\\\\\\\\n",
    "&= \\binom{|\\mathbf{x}|}{\\mathbf{x}} \\frac{\\Gamma(|\\alpha|)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)} \\prod_{j=1}^d p_j^{x_j + \\alpha_j-1}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "This implies \n",
    "$$\n",
    "\\begin{align}\n",
    "p(\\mathbf{x}\\,|\\,\\mathbf{\\alpha}) &= \\int_{\\Delta_d}p(\\mathbf{x},\\mathbf{p}\\,|\\,\\mathbf{\\alpha})\\,d\\mathbf{p}\\\\\\\\\n",
    "&= \\binom{|\\mathbf{x}|}{\\mathbf{x}} \\frac{\\Gamma(|\\alpha|)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)}\\int_{\\Delta_d}\\prod_{j=1}^d p_j^{x_j + \\alpha_j-1}\\,d\\mathbf{p}\\\\\\\\\n",
    "&= \\binom{|\\mathbf{x}|}{\\mathbf{x}} \\frac{\\Gamma(|\\alpha|)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)}\\frac{\\prod_{j=1}^d \\Gamma(x_j+\\alpha_j)}{\\Gamma(|\\mathbf{x}|+|\\alpha|)}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
=======
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2\n",
    "\n",
    "The log-likelihood is\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L(\\alpha) &= \\log(p(\\mathbf{x}\\,|\\,\\alpha))\\\\\\\\\n",
    "&=\\log\\bigg[\\binom{|\\mathbf{x}|}{\\mathbf{x}} \\frac{\\Gamma(|\\alpha|)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)}\\frac{\\prod_{j=1}^d \\Gamma(x_j+\\alpha_j)}{\\Gamma(|\\mathbf{x}|+|\\alpha|)}\\bigg]\\\\\\\\\n",
    "&=\\log\\bigg[\\binom{|\\mathbf{x}|}{\\mathbf{x}}\\bigg] + \\log\\bigg[\\frac{\\prod_{j=1}^{d}\\Gamma(x_j+\\alpha_j}{\\prod_{j=1}^{d}\\Gamma(\\alpha_j)}\\bigg] + \\log\\bigg[\\frac{\\Gamma(|\\alpha|)}{\\Gamma(|\\mathbf{x}|+|\\alpha|)}\\bigg]\\\\\\\\\n",
    "&=\\log\\bigg[\\binom{|\\mathbf{x}|}{\\mathbf{x}}\\bigg] + \\sum_{j=1}^{d}\\bigg[\\log\\Gamma(x_j+\\alpha_j)-\\log\\Gamma(\\alpha_j)\\bigg] - \\bigg[\\log\\Gamma(|x|+|\\alpha|)-\\log\\Gamma(|\\alpha|)\\bigg]\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "For indpendent $\\mathbf{x_1}, \\mathbf{x_2},\\ldots,\\mathbf{x_n}$ the log-likelihood becomes \n",
    "\n",
    "$$\\sum_{i=1}^{n}\\log\\bigg[\\binom{|\\mathbf{x_i}|}{\\mathbf{x_i}}\\bigg] + \\sum_{i=1}^{n}\\sum_{j=1}^{d}\\bigg[\\log\\Gamma(x_{ij}+\\alpha_j)-\\log\\Gamma(\\alpha_j)\\bigg] - \\sum_{i=1}^{n}\\bigg[\\log\\Gamma(|\\mathbf{x_i}|+|\\alpha|)-\\log\\Gamma(|\\alpha|)\\bigg]$$\n",
    "\n",
    "\n",
    "The log-likelihood is not concave. I will show the hessian matrix is not always negative definite.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{d^2}{d\\alpha_1^2}L(\\alpha\\,|\\,\\mathbf{x}) = \\psi_1(x_1+\\alpha_1)-\\psi_1(\\alpha_1)-\\psi_1(x_1+x_2+\\alpha_1+\\alpha_2)+\\psi_1(\\alpha_1+\\alpha_2)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Where $\\psi_1$ is the trigamma function.\n",
    "\n",
    "Let $n=1, \\alpha_1 = 10, \\alpha_2=1,x_1=1,x_2=2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021126067017675415"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "α1 = 10\n",
    "α2 = 1\n",
    "x1 = 1\n",
    "x2 = 2\n",
    "trigamma(x1 + α1) - trigamma(α1) \n",
    "- trigamma(x1 + x2 + α1 + α2) + trigamma(α1 + α2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $\\displaystyle\\frac{d^2}{d\\alpha_1^2}L(\\alpha\\,|\\,\\mathbf{x}) > 0$, a diagonal term of the hessian is positive. Therefore the hessian is not always negative definite. The log-likelihood is not concave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dirmult_logpdf"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    dirmult_logpdf(x::Vector, α::Vector)\n",
    "    \n",
    "Compute the log-pdf of Dirichlet-multinomial distribution with parameter `α` \n",
    "at data point `x`.\n",
    "\"\"\"\n",
    "function dirmult_logpdf(x::Vector, α::Vector)\n",
    "    s = 0\n",
    "    result = 0\n",
    "    for i in 1:length(x)\n",
    "        #s += x[i]\n",
    "        #result += sum(log(1:s)) - sum(log(1:x[i])) - sum(log(1:(s - x[i])))\n",
    "        result += - lfact(x[i])\n",
    "    end\n",
    "\n",
    "    storage = 0\n",
    "    for i in 1:length(x)\n",
    "        storage += lgamma(x[i] + α[i]) - lgamma(α[i])\n",
    "    end\n",
    "    #print(lgamma(α[1]))\n",
    "    return result + storage - lgamma(sum(α) + sum(x)) + lgamma(sum(α)) + lfact(sum(x))\n",
    "end\n",
    "\n",
    "function dirmult_logpdf!(r::Vector, X::Matrix, α::Vector)\n",
    "    for j in 1:size(X, 2)\n",
    "        r[j] = dirmult_logpdf(X[:, j], α)\n",
    "    end\n",
    "    return r\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    dirmult_logpdf(X, α)\n",
    "    \n",
    "Compute the log-pdf of Dirichlet-multinomial distribution with parameter `α` \n",
    "at each data point in `X`. Each column of `X` is one data point.\n",
    "\"\"\"\n",
    "function dirmult_logpdf(X::Matrix, α::Vector)\n",
    "    r = zeros(size(X, 2))\n",
    "    dirmult_logpdf!(r, X, α)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optdigits = readcsv(\"E:/Classes/BiostatisticsM280/Submissions/biostat-m280-JohnShamshoian/HW4/optdigits.tra\")\n",
    "training = Int64.(optdigits[:, 1:64]);\n",
    "trainingdigits = Int64.(optdigits[:, 65]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3823-element Array{Float64,1}:\n",
       " -165.188\n",
       " -176.23 \n",
       " -167.774\n",
       " -165.564\n",
       " -157.79 \n",
       " -176.071\n",
       " -158.423\n",
       " -159.258\n",
       " -174.302\n",
       " -178.407\n",
       " -171.294\n",
       " -169.383\n",
       " -175.753\n",
       "    ⋮    \n",
       " -160.49 \n",
       " -158.633\n",
       " -156.935\n",
       " -171.975\n",
       " -177.638\n",
       " -169.735\n",
       " -158.423\n",
       " -159.465\n",
       " -159.877\n",
       " -169.735\n",
       " -173.149\n",
       " -155.411"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirmult_logpdf(training', [1; ones(Int64, 63)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5\n",
    "\n",
    "The score function is $\\nabla L(\\alpha) = \\displaystyle\\frac{d}{d\\mathbf{\\alpha}}L(\\alpha)$, where \n",
    "\n",
    "$$\\displaystyle\\frac{d}{d\\alpha_j}L(\\alpha)=\\sum_{i=1}^{n}\\bigg[\\psi(x_{ij} + \\alpha_j)-\\psi(\\alpha_j)\\bigg]-\\sum_{i=1}^{n}\\bigg[\\psi(|\\mathbf{x_i}| + |\\alpha|)-\\psi(|\\alpha|)\\bigg]$$\n",
    "\n",
    "$\\psi$ is the digamma function.\n",
    "\n",
    "The observed information is $-d^{2}L(\\alpha)$, where\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\big[-d^{2}L(\\alpha))\\big]_{kj} &= -\\frac{d}{d\\alpha_k\\alpha_j}L(\\alpha)\\\\\\\\\n",
    "&=\\begin{cases}\n",
    "  \\displaystyle\\sum_{i=1}^{n}\\bigg[\\psi_{1}(|\\mathbf{x_i}|+|\\alpha|) - \\psi_1(|\\alpha|)\\bigg]-\\displaystyle\\sum_{i=1}^{n}\\bigg[\\psi_{1}(x_{ij}+\\alpha_j)-\\psi_1(\\alpha_j)\\bigg] & \\text{if }k = j\\\\\\\\\n",
    " \\displaystyle\\sum_{i=1}^{n}\\bigg[\\psi_{1}(|\\mathbf{x_i}|+|\\alpha|) - \\psi_1(|\\alpha|)\\bigg] & \\text{if }k\\neq j\n",
    "\\end{cases}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "To derive the expected information matrix $\\mathbb{E}[-d^{2}L(\\alpha)]$ I will use the alternate form of the log-likelihood from homework 5.\n",
    "\n",
    "$$\n",
    "L(\\alpha) = \\sum_{i=1}^{n}\\ln\\binom{|\\mathbf{x_i}|}{\\mathbf{x_i}} + \\sum_{i=1}^{n}\\sum_{j=1}^{d}\\sum_{k=0}^{x_{ij}-1}\\ln(\\alpha_j+k)-\\sum_{i=1}^{n}\\sum_{k=0}^{|\\mathbf{x_i}|-1}\\ln(|\\alpha|+k)\n",
    "$$\n",
    "\n",
    "For $k\\neq j$,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}[-d^{2}L(\\alpha)]_{kj} &=- \\sum_{i=1}^{n}\\sum_{x_{i1},\\ldots,x_{id}}^{|\\mathbf{x_i}|}\\sum_{k=0}^{|\\mathbf{x_i}|-1}\\frac{1}{(|\\alpha|+k)^2}p(\\mathbf{x_i})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "And for $k=j$,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}[-d^{2}L(\\alpha)]_{kj}=\\sum_{i=1}^{n}\\sum_{x_{i1}\\ldots,x_{id}}^{|\\mathbf{x_i}|}\\sum_{k=0}^{x_{ij}-1}\\frac{1}{(\\alpha_{j}+k)^2}p(\\mathbf{x_i})-\\sum_{i=1}^{n}\\sum_{x_{i1}\\ldots,x_{id}}^{|\\mathbf{x_i}|}\\sum_{k=0}^{|\\mathbf{x_i}|-1}\\frac{1}{(|\\alpha|+k)^2}p(\\mathbf{x_i})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Fisher scoring is inefficient because the triple summation would take a while to compute for each iteration of the newton-raphson algorithm. It's easier to approximate the observed information matrix with a different positive definite matrix, as seen in the next problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6\n",
    "\n",
    "The observed information matrix has the structure $D+11'c$, where $D$ is a $d\\times d$ diagonal matrix with positive entries, $c$ is a negative constant, and $1$ is a $d\\times 1$ vector of ones.\n",
    "\n",
    "$D+11'c$ is positive definite if and only if $(D+11'c)^{-1} = D^{-1} - c\\displaystyle\\frac{D^{-1}11'D^{-1}}{1+c1'D^{-1}1}$ is positive definite.\n",
    "\n",
    "From this expression I see that if $1+c1'D^{-1}1 > 0$, then $(D+11'c)^{-1}$ is positive definite.\n",
    "\n",
    "If $1+c1'D^{-1}1 \\leq 0$, replace $c$ with $-.95\\frac{1}{1'D^{-1}1}$\n",
    "\n",
    "Since this adjustment guarantees $(D+11'c)^{-1}$ is positive definite, this adjustment guarantees $D + 11'c$ is positive definite as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7\n",
    "\n",
    "The $p_{1},\\ldots,p_d$ follow a dirichlet distribution, so $\\mathbb{E}[p_j] = \\displaystyle\\frac{\\alpha_j}{|\\alpha|}$\n",
    "\n",
    "$Var(p_j) = \\displaystyle\\frac{\\alpha_j(|\\alpha|-\\alpha_j)}{|\\alpha|^2(|\\alpha| + 1)}$\n",
    "\n",
    "From which I see that $\\mathbb{E}[p_j^2] = \\displaystyle\\frac{\\alpha_i (1+\\alpha_i)}{|\\alpha|(|\\alpha|+1)}$\n",
    "\n",
    "Marginally, each $p_j \\sim Beta(a_i, b_i)$, where $a_j = \\alpha_j$ and $b_j = |\\alpha| - \\alpha_j$\n",
    "\n",
    "The moments of the beta distribution are similar to the dirichlet, with $\\mu_1 = \\mathbb{E}[p_j] = \\displaystyle\\frac{a_j}{a_j + b_j}$ and $\\mu_2 = \\mathbb{E}[p_j^2] = \\displaystyle\\frac{a_j(a_j+1)}{(a_j + b_j)(a_j + b_j + 1)}$.\n",
    "\n",
    "Solving for $a_j$ is easy: $a_j = \\displaystyle\\frac{\\mu_1(\\mu_1-\\mu_2)}{\\mu_2-\\mu_1^2}$\n",
    "\n",
    "I can estimate $\\mu_1$ by $\\hat{\\mu}_1 = \\displaystyle\\frac{1}{N}\\sum_{i=1}^{N}X_{i}$ and $\\hat{\\mu}_2 = \\displaystyle\\frac{1}{N}\\sum_{i=1}^{N}X_i^2$, where $X_i$ is the proportion in the $i^{th}$ sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dirmult_newton"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using WoodburyMatrices\n",
    "\"\"\"\n",
    "    dirmult_newton(X)\n",
    "\n",
    "Find the MLE of Dirichlet-multinomial distribution using Newton's method.\n",
    "\n",
    "# Argument\n",
    "* `X`: an `n`-by-`d` matrix of counts; each column is one data point.\n",
    "\n",
    "# Optional argument  \n",
    "* `alpha0`: a `d` vector of starting point (optional). \n",
    "* `maxiters`: the maximum allowable Newton iterations (default 100). \n",
    "* `tolfun`: the tolerance for  relative change in objective values (default 1e-6). \n",
    "\n",
    "# Output\n",
    "* `maximum`: the log-likelihood at MLE.   \n",
    "* `estimate`: the MLE. \n",
    "* `gradient`: the gradient at MLE. \n",
    "* `hessian`: the Hessian at MLE. \n",
    "* `se`: a `d` vector of standard errors. \n",
    "* `iterations`: the number of iterations performed.\n",
    "\"\"\"\n",
    "function dirmult_newton(X::Matrix; α0::Vector = nothing, \n",
    "            maxiters::Int = 100, tolfun::Float64 = 1e-6)\n",
    "    \n",
    "    # Retain only columns with non-zero sum. Skipping this step will make the hessian singular.\n",
    "    #X = X[:, findnz(sum(X,1))[2]]\n",
    "    \n",
    "    c = 0.0\n",
    "    n, m = size(X)\n",
    "    \n",
    "    # set default starting point from Q7\n",
    "\n",
    "    # Method of moments estimator for α\n",
    "    prop = diagm(vec(1 ./ sum(X, 2))) * X\n",
    "    μ1 = sum(prop, 1) / n\n",
    "    μ2 = sum(prop.^2, 1) / n\n",
    "    for i in 1:m\n",
    "        α0[i] = μ1[i] * (μ1[i] - μ2[i]) / (μ2[i] - μ1[i]^2)\n",
    "    end\n",
    "    \n",
    "    # Initialize gradient vector\n",
    "    gradient = zeros(m)\n",
    "    \n",
    "    # Initialize diagonal from Q6 notation\n",
    "    D = Diagonal(zeros(m))\n",
    "    \n",
    "    # Initialize hessian\n",
    "    H = Array(Float64, m, m)\n",
    "    \n",
    "    # Compute initial log-likelihood\n",
    "    loglold = sum(dirmult_logpdf(X', α0))\n",
    "    \n",
    "    # Initialize variable to store new log-likelihood\n",
    "    logl = loglold\n",
    "    counter = 0\n",
    "    #tolfun = 1e-6\n",
    "    \n",
    "    # Initialize stepsize\n",
    "    stepsize = 1\n",
    "    \n",
    "    # Initialize αtry vector. This will be used to select a good stepsize in line search\n",
    "    αtry = zeros(m)\n",
    "    \n",
    "    # Initialize vector of ones\n",
    "    z = ones(m)\n",
    "    logltry = Float64\n",
    "    itercount = 0\n",
    "    \n",
    "    # Newton loop\n",
    "    for iter in 1:maxiters\n",
    "        \n",
    "        loglold = logl\n",
    "        \n",
    "        # Compute gradient as in Q5\n",
    "        for j in 1:n\n",
    "            for i in 1:m\n",
    "                gradient[i] = gradient[i] + digamma(X[j, i] + α0[i]) -\n",
    "                digamma(α0[i]) - digamma(sum(X[j, :]) + sum(α0)) + digamma(sum(α0))\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        # approximated observed information matrix\n",
    "        \n",
    "        # Compute c as in Q6\n",
    "        for j in 1:n\n",
    "            c = c + trigamma(sum(X[j, :]) + sum(α0))\n",
    "        end\n",
    "        \n",
    "        c = c - n * trigamma(sum(α0))\n",
    "        \n",
    "        # Compute D as in Q6\n",
    "        for i = 1:m\n",
    "            for j in 1:n   \n",
    "                D[i, i] = D[i, i] - trigamma(α0[i] + X[j, i]) \n",
    "            end\n",
    "            D[i, i] = D[i, i] + n * trigamma(α0[i]) \n",
    "        end\n",
    "        \n",
    "        # Check if negative hessian is positive definite\n",
    "        # If not pd, overwrite c to make it pd\n",
    "        if (1 + c * dot(z, D \\ z)) <= 0\n",
    "            c = -.95 * 1 / dot(z, D \\ z)\n",
    "        end\n",
    "            \n",
    "        # This is the negative of the hessian\n",
    "        # It's positive definite\n",
    "        H = Woodbury(D, z, 1.0, z' * c)\n",
    "        \n",
    "        # line search loop\n",
    "        for lsiter in 1:10\n",
    "            s = (2.0)^(- 2 * lsiter + 2)\n",
    "                \n",
    "            # Let's see if this αtry is a good update\n",
    "            αtry = α0 + H \\ (gradient * s)\n",
    "            logltry = sum(dirmult_logpdf(X', αtry))\n",
    "            \n",
    "            # If αtry is a good update, keep it\n",
    "            if (logltry > logl) & (minimum(αtry) > 0)\n",
    "                stepsize = s\n",
    "                break;\n",
    "            end\n",
    "        end\n",
    "    \n",
    "        # compute Newton's direction\n",
    "        α0 = α0 + H \\ (gradient * stepsize)\n",
    "        logl = sum(dirmult_logpdf(X', α0))\n",
    "        \n",
    "        # Check convergence criteria\n",
    "        if abs(logl - loglold) < (tolfun * (abs(loglold) + 1))\n",
    "            break;\n",
    "        end\n",
    "        \n",
    "        # If it convergence criteria is not reached, overwrite\n",
    "        # loglold and start again\n",
    "        # Overwrite gradient and diagonal\n",
    "        for i in 1:m\n",
    "            gradient[i] = 0.0\n",
    "            D[i, i] = 0.0\n",
    "        end\n",
    "        \n",
    "        itercount += 1\n",
    "        \n",
    "    end\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return logl, α0, gradient, - full(H), sqrt(diag(full(H))), itercount  \n",
    "\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a matrix to hold all the MLEs\n",
    "mlematrix = Matrix(64, 10)\n",
    "\n",
    "for digit in 0:9\n",
    "    iter = 1\n",
    "    \n",
    "    # Get MLE vector for a particular digit\n",
    "    digitsets = training[trainingdigits .== digit, :]\n",
    "    X = digitsets[:, findnz(sum(digitsets,1))[2]]\n",
    "    m = size(X, 2)\n",
    "    \n",
    "    # Run the newton raphson algorithm to get MLE\n",
    "    currentmle = dirmult_newton(X, α0 = Vector(m))[2]\n",
    "    \n",
    "    for i in 1:64\n",
    "        if in(i, findnz(sum(digitsets, 1))[2])\n",
    "            mlematrix[i, digit + 1] = currentmle[iter]\n",
    "            iter += 1\n",
    "        else\n",
    "            # Let zero denote a parameter that could not be estimated.\n",
    "            # This happens when there's zero count for a block of 16 pixels\n",
    "            mlematrix[i, digit + 1] = 0\n",
    "        end\n",
    "        \n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>ParameterEst</th><th>parameterdigit0</th><th>digit1</th><th>digit2</th><th>digit3</th><th>digit4</th><th>digit5</th><th>digit6</th><th>digit7</th><th>digit8</th><th>digit9</th></tr></thead><tbody><tr><th>1</th><td>α1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>2</th><td>α2</td><td>0.03748804960555175</td><td>0.008042746447711968</td><td>0.38696375808704203</td><td>0.46265946657378715</td><td>0.008026063253141806</td><td>0.19115360138063725</td><td>0.0049639169180514565</td><td>0.14021033358050805</td><td>0.08803131721555699</td><td>0.07654093859147748</td></tr><tr><th>3</th><td>α3</td><td>4.999732367513544</td><td>0.5156189962038383</td><td>3.7917203396969428</td><td>4.377214311046461</td><td>0.11933649253575118</td><td>2.543014699540174</td><td>0.8790430530134116</td><td>2.510993374346913</td><td>2.499539710559785</td><td>1.5332498693807783</td></tr><tr><th>4</th><td>α4</td><td>14.916296334140329</td><td>2.1068280516672564</td><td>5.210215817684139</td><td>7.011423825362884</td><td>1.57966154984904</td><td>4.19233366502388</td><td>5.903638400150657</td><td>5.088734426480402</td><td>5.837873806617221</td><td>3.709653251825837</td></tr><tr><th>5</th><td>α5</td><td>12.180855490575041</td><td>3.068136843422291</td><td>2.4944979328396264</td><td>6.540924021630484</td><td>2.8997771867297644</td><td>4.503823550211866</td><td>3.7140425131886516</td><td>5.483940356133259</td><td>5.586543959086269</td><td>3.742057449960118</td></tr><tr><th>6</th><td>α6</td><td>2.4591758584864825</td><td>1.3259471780734802</td><td>0.30928027428821186</td><td>2.395581274591998</td><td>0.5298938630288852</td><td>3.4994680301309042</td><td>0.4286664397224917</td><td>4.489642949782418</td><td>2.4248781616694894</td><td>1.5173174088313577</td></tr><tr><th>7</th><td>α7</td><td>0.06359208877091448</td><td>0.1381100704216468</td><td>0.015717064904677655</td><td>0.18957551180516832</td><td>0.07651028585810238</td><td>0.8299065624924734</td><td>0</td><td>1.7302228774272284</td><td>0.19982849573913186</td><td>0.2991615478321928</td></tr><tr><th>8</th><td>α8</td><td>0</td><td>0</td><td>0</td><td>0.009162669341985579</td><td>0.03180367753839045</td><td>0.014623121261743144</td><td>0</td><td>0.1797150927769054</td><td>0</td><td>0.015969912141365124</td></tr><tr><th>9</th><td>α9</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.0035742573475080652</td><td>0</td><td>0</td><td>0.0021989187040730804</td><td>0</td></tr><tr><th>10</th><td>α10</td><td>1.0250077314784236</td><td>0.05741254874719832</td><td>1.722911084367515</td><td>1.8949770204945542</td><td>0.028282430812558934</td><td>0.7414652799950522</td><td>0.06039491478631157</td><td>0.2559564100489872</td><td>1.0235742159942176</td><td>0.6681709177406464</td></tr><tr><th>11</th><td>α11</td><td>14.617551027757097</td><td>1.0444146612729421</td><td>5.46358191620328</td><td>6.477714550657065</td><td>0.5841603041712689</td><td>4.522313996630327</td><td>4.2106601194180575</td><td>3.194382645768315</td><td>6.108656128900131</td><td>4.028923872905161</td></tr><tr><th>12</th><td>α12</td><td>14.778363544596647</td><td>3.252496133809527</td><td>4.722173037290247</td><td>4.6523448643126</td><td>3.2072464769390336</td><td>4.111495583550692</td><td>7.399517789948966</td><td>4.014174979406193</td><td>4.566997208976422</td><td>3.35695611030156</td></tr><tr><th>13</th><td>α13</td><td>13.763900334847937</td><td>4.1204763649082325</td><td>4.413822341790742</td><td>5.871629270290044</td><td>2.2348625209827646</td><td>3.0206854136902948</td><td>2.440716059857879</td><td>4.195005447032448</td><td>4.089955031557491</td><td>3.2971662171965552</td></tr><tr><th>14</th><td>α14</td><td>11.957106297572588</td><td>2.235335429554107</td><td>1.0056944874541045</td><td>5.028870385584088</td><td>0.5340012685389929</td><td>2.4357701008112778</td><td>0.35763189159137715</td><td>5.035596270246677</td><td>5.237598383742827</td><td>3.4776507732023263</td></tr><tr><th>15</th><td>α15</td><td>0.5465665877241257</td><td>0.17973244067796498</td><td>0.045397159255788896</td><td>0.4435414809080257</td><td>0.3262428859626641</td><td>0.6359041778907295</td><td>0</td><td>2.1984627247538615</td><td>0.8204499108025508</td><td>0.7286089520913432</td></tr><tr><th>16</th><td>α16</td><td>0</td><td>0</td><td>0</td><td>0.011481871209100483</td><td>0.0742600827017131</td><td>0.00899406130902302</td><td>0</td><td>0.16404363950569048</td><td>0</td><td>0.03655321871675837</td></tr><tr><th>17</th><td>α17</td><td>0</td><td>0.00648702106954679</td><td>0</td><td>0</td><td>0</td><td>0.007148487374869014</td><td>0</td><td>0</td><td>0.002188906279731596</td><td>0</td></tr><tr><th>18</th><td>α18</td><td>4.172238458336859</td><td>0.24032737735101725</td><td>1.3499176903534558</td><td>0.6339555259021081</td><td>0.202737547235706</td><td>1.2046007780905037</td><td>0.43766729814476085</td><td>0.08948035980254272</td><td>1.417090176606509</td><td>1.2014237317060452</td></tr><tr><th>19</th><td>α19</td><td>16.2879214435588</td><td>1.9272339176158482</td><td>2.8013715695709953</td><td>1.2562036039002809</td><td>2.055253863175552</td><td>4.475281129566765</td><td>6.8551592460998805</td><td>0.29102687784060266</td><td>5.60430989864416</td><td>4.177988448326008</td></tr><tr><th>20</th><td>α20</td><td>4.5471285143901605</td><td>4.098886489101608</td><td>1.2224550801422855</td><td>1.2447879767967753</td><td>3.205166860485437</td><td>1.8574819781939773</td><td>4.4140260458411555</td><td>0.22685696393094643</td><td>2.3131378649741183</td><td>1.461615669068878</td></tr><tr><th>21</th><td>α21</td><td>2.577922727021759</td><td>4.181017355120964</td><td>3.9587714302032793</td><td>5.662220484857127</td><td>0.9354266948802341</td><td>0.5577982543568392</td><td>0.23517020663381222</td><td>1.994335452868101</td><td>3.373308311530694</td><td>2.460554231937297</td></tr><tr><th>22</th><td>α22</td><td>14.414087256063807</td><td>1.8612559160762063</td><td>1.4432884678728732</td><td>4.124891547416681</td><td>1.3036511525492611</td><td>0.18063050825922788</td><td>0.004992117441945662</td><td>4.623862229053792</td><td>5.04110751004506</td><td>4.477982103424955</td></tr><tr><th>23</th><td>α23</td><td>3.5806850180946874</td><td>0.10730887787383701</td><td>0.06993756752239016</td><td>0.23177519206482755</td><td>0.9086845727308352</td><td>0.027290563584015888</td><td>0.002475843866827104</td><td>1.1737317081843115</td><td>0.7918009781130018</td><td>1.072202133970558</td></tr><tr><th>24</th><td>α24</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.06173698492536931</td><td>0</td><td>0</td><td>0.04179454540413182</td><td>0</td><td>0.017870951365368256</td></tr><tr><th>25</th><td>α25</td><td>0</td><td>0.0064239145249216905</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>26</th><td>α26</td><td>5.925694106316083</td><td>0.5125102209862126</td><td>0.2821943493178251</td><td>0.04761482742156909</td><td>0.930656588157714</td><td>1.3075394752285714</td><td>1.0351828881262477</td><td>0.13154370020377087</td><td>0.5112084353980011</td><td>0.6450459616660551</td></tr><tr><th>27</th><td>α27</td><td>14.406412590285598</td><td>2.605033046764804</td><td>0.59094935319995</td><td>0.6923345991804206</td><td>3.6795845043747186</td><td>4.235641770053551</td><td>7.566099419378245</td><td>0.9499239572177699</td><td>4.331661090613572</td><td>3.1882428490450896</td></tr><tr><th>28</th><td>α28</td><td>1.2107766277828793</td><td>4.08996387922324</td><td>1.250566387328383</td><td>4.954885668754888</td><td>2.3486876548595714</td><td>3.7105225088311604</td><td>3.264818294888219</td><td>2.246442500182776</td><td>6.186172686991321</td><td>3.362571499690912</td></tr><tr><th>29</th><td>α29</td><td>0.1539244899832254</td><td>4.113573576280732</td><td>4.10044484750984</td><td>7.076179045032388</td><td>1.2102316340953645</td><td>2.3730526744089295</td><td>0.9324703720150653</td><td>4.702085640197338</td><td>6.106562169994216</td><td>3.798800532050736</td></tr><tr><th>30</th><td>α30</td><td>10.338255551027336</td><td>1.681894517620938</td><td>1.1251385038670219</td><td>2.6492233995696446</td><td>3.1490925945768202</td><td>0.8640342155035068</td><td>0.3752777145486213</td><td>4.5958546978290045</td><td>2.6376872924522434</td><td>4.657053180166062</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/plain": [
       "64×11 DataFrames.DataFrame\n",
       "│ Row │ ParameterEst │ parameterdigit0 │ digit1     │ digit2     │ digit3     │\n",
       "├─────┼──────────────┼─────────────────┼────────────┼────────────┼────────────┤\n",
       "│ 1   │ \"α1\"         │ 0               │ 0          │ 0          │ 0          │\n",
       "│ 2   │ \"α2\"         │ 0.037488        │ 0.00804275 │ 0.386964   │ 0.462659   │\n",
       "│ 3   │ \"α3\"         │ 4.99973         │ 0.515619   │ 3.79172    │ 4.37721    │\n",
       "│ 4   │ \"α4\"         │ 14.9163         │ 2.10683    │ 5.21022    │ 7.01142    │\n",
       "│ 5   │ \"α5\"         │ 12.1809         │ 3.06814    │ 2.4945     │ 6.54092    │\n",
       "│ 6   │ \"α6\"         │ 2.45918         │ 1.32595    │ 0.30928    │ 2.39558    │\n",
       "│ 7   │ \"α7\"         │ 0.0635921       │ 0.13811    │ 0.0157171  │ 0.189576   │\n",
       "│ 8   │ \"α8\"         │ 0               │ 0          │ 0          │ 0.00916267 │\n",
       "│ 9   │ \"α9\"         │ 0               │ 0          │ 0          │ 0          │\n",
       "│ 10  │ \"α10\"        │ 1.02501         │ 0.0574125  │ 1.72291    │ 1.89498    │\n",
       "│ 11  │ \"α11\"        │ 14.6176         │ 1.04441    │ 5.46358    │ 6.47771    │\n",
       "⋮\n",
       "│ 53  │ \"α53\"        │ 11.7434         │ 4.06461    │ 4.36751    │ 3.97459    │\n",
       "│ 54  │ \"α54\"        │ 15.2609         │ 2.28187    │ 3.81788    │ 6.91064    │\n",
       "│ 55  │ \"α55\"        │ 2.59461         │ 0.27363    │ 2.35243    │ 2.60624    │\n",
       "│ 56  │ \"α56\"        │ 0               │ 0.0303925  │ 0.135601   │ 0.0182335  │\n",
       "│ 57  │ \"α57\"        │ 0               │ 0          │ 0.00192913 │ 0          │\n",
       "│ 58  │ \"α58\"        │ 0.0207874       │ 0.0177782  │ 0.353442   │ 0.32243    │\n",
       "│ 59  │ \"α59\"        │ 5.03306         │ 0.516189   │ 3.86193    │ 4.73346    │\n",
       "│ 60  │ \"α60\"        │ 15.3981         │ 2.02671    │ 5.23031    │ 7.30304    │\n",
       "│ 61  │ \"α61\"        │ 15.0959         │ 3.53588    │ 4.90531    │ 6.5052     │\n",
       "│ 62  │ \"α62\"        │ 5.83143         │ 2.21661    │ 4.49153    │ 3.45913    │\n",
       "│ 63  │ \"α63\"        │ 0.194638        │ 0.409596   │ 3.00125    │ 0.479264   │\n",
       "│ 64  │ \"α64\"        │ 0               │ 0.0420217  │ 0.33326    │ 0.00226656 │\n",
       "\n",
       "│ Row │ digit4     │ digit5     │ digit6     │ digit7    │ digit8     │\n",
       "├─────┼────────────┼────────────┼────────────┼───────────┼────────────┤\n",
       "│ 1   │ 0          │ 0          │ 0          │ 0         │ 0          │\n",
       "│ 2   │ 0.00802606 │ 0.191154   │ 0.00496392 │ 0.14021   │ 0.0880313  │\n",
       "│ 3   │ 0.119336   │ 2.54301    │ 0.879043   │ 2.51099   │ 2.49954    │\n",
       "│ 4   │ 1.57966    │ 4.19233    │ 5.90364    │ 5.08873   │ 5.83787    │\n",
       "│ 5   │ 2.89978    │ 4.50382    │ 3.71404    │ 5.48394   │ 5.58654    │\n",
       "│ 6   │ 0.529894   │ 3.49947    │ 0.428666   │ 4.48964   │ 2.42488    │\n",
       "│ 7   │ 0.0765103  │ 0.829907   │ 0          │ 1.73022   │ 0.199828   │\n",
       "│ 8   │ 0.0318037  │ 0.0146231  │ 0          │ 0.179715  │ 0          │\n",
       "│ 9   │ 0          │ 0.00357426 │ 0          │ 0         │ 0.00219892 │\n",
       "│ 10  │ 0.0282824  │ 0.741465   │ 0.0603949  │ 0.255956  │ 1.02357    │\n",
       "│ 11  │ 0.58416    │ 4.52231    │ 4.21066    │ 3.19438   │ 6.10866    │\n",
       "⋮\n",
       "│ 53  │ 3.68598    │ 3.39323    │ 3.18867    │ 1.56639   │ 3.34852    │\n",
       "│ 54  │ 1.23207    │ 2.49829    │ 5.85476    │ 0.0533539 │ 4.03825    │\n",
       "│ 55  │ 0.0694227  │ 0.318553   │ 6.01871    │ 0.0019217 │ 0.776959   │\n",
       "│ 56  │ 0.00160608 │ 0.00718036 │ 0.324731   │ 0         │ 0          │\n",
       "│ 57  │ 0          │ 0          │ 0          │ 0         │ 0          │\n",
       "│ 58  │ 0.0259814  │ 0.139938   │ 0.0148914  │ 0.0996265 │ 0.0780438  │\n",
       "│ 59  │ 0.12748    │ 2.69876    │ 1.00677    │ 2.85553   │ 2.57595    │\n",
       "│ 60  │ 1.6944     │ 4.62133    │ 5.80906    │ 4.14482   │ 6.17477    │\n",
       "│ 61  │ 2.96279    │ 3.20598    │ 8.09049    │ 0.453607  │ 5.71705    │\n",
       "│ 62  │ 0.503032   │ 0.837438   │ 7.00883    │ 0.0118084 │ 2.69317    │\n",
       "│ 63  │ 0.011424   │ 0.0687729  │ 2.55308    │ 0         │ 0.300095   │\n",
       "│ 64  │ 0.00160767 │ 0.00356793 │ 0.119228   │ 0         │ 0.00660747 │\n",
       "\n",
       "│ Row │ digit9    │\n",
       "├─────┼───────────┤\n",
       "│ 1   │ 0         │\n",
       "│ 2   │ 0.0765409 │\n",
       "│ 3   │ 1.53325   │\n",
       "│ 4   │ 3.70965   │\n",
       "│ 5   │ 3.74206   │\n",
       "│ 6   │ 1.51732   │\n",
       "│ 7   │ 0.299162  │\n",
       "│ 8   │ 0.0159699 │\n",
       "│ 9   │ 0         │\n",
       "│ 10  │ 0.668171  │\n",
       "│ 11  │ 4.02892   │\n",
       "⋮\n",
       "│ 53  │ 2.22884   │\n",
       "│ 54  │ 2.62574   │\n",
       "│ 55  │ 0.986871  │\n",
       "│ 56  │ 0.0160078 │\n",
       "│ 57  │ 0         │\n",
       "│ 58  │ 0.0536442 │\n",
       "│ 59  │ 1.46886   │\n",
       "│ 60  │ 3.77286   │\n",
       "│ 61  │ 3.5667    │\n",
       "│ 62  │ 1.6203    │\n",
       "│ 63  │ 0.3364    │\n",
       "│ 64  │ 0.0070327 │"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = Vector(64)\n",
    "for i in 1:64\n",
    "    param[i] = string(\"α\", i)\n",
    "end\n",
    "\n",
    "# Display the first 30 MLEs\n",
    "DataFrame(ParameterEst = param, parameterdigit0 = mlematrix[:, 1],\n",
    "    digit1 = mlematrix[:, 2],\n",
    "digit2 = mlematrix[:, 3], digit3 = mlematrix[:, 4],\n",
    "digit4 = mlematrix[:, 5], digit5 = mlematrix[:, 6],\n",
    "digit6 = mlematrix[:, 7], digit7 = mlematrix[:, 8],\n",
    "digit8 = mlematrix[:, 9], digit9 = mlematrix[:, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I printed out the first 30 MLEs for each digit. A value of zero denotes the parameter could not be estimated due to lack of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mult_logpdf"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute log-likelihood of multinomial in a similar vein\n",
    "# to dirichlet multinomial log-likelihood\n",
    "function mult_logpdf!(r::Vector, X::Matrix, p::Vector)\n",
    "    for j in 1:size(X, 2)\n",
    "        d = Multinomial(sum(X[:, j]), p)\n",
    "        r[j] = logpdf(d, X[j, :])\n",
    "    end\n",
    "    return r\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    mult_logpdf(X, α)\n",
    "    \n",
    "Compute the log-pdf of multinomial distribution with parameter `p` \n",
    "at each data point in `X`. Each column of `X` is one data point.\n",
    "\"\"\"\n",
    "function mult_logpdf(X::Matrix, p::Vector)\n",
    "    r = zeros(size(X, 2))\n",
    "    dirmult_logpdf!(r, X, p)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>Digit</th><th>loglikDirichletMultinomial</th><th>loglikMultinomial</th><th>TestStat</th></tr></thead><tbody><tr><th>1</th><td>0</td><td>-37358.42</td><td>-76611.51</td><td>78506.17</td></tr><tr><th>2</th><td>1</td><td>-42179.3</td><td>-69330.65</td><td>54302.71</td></tr><tr><th>3</th><td>2</td><td>-39985.35</td><td>-69257.17</td><td>58543.64</td></tr><tr><th>4</th><td>3</td><td>-40519.47</td><td>-73718.29</td><td>66397.63</td></tr><tr><th>5</th><td>4</td><td>-43488.8</td><td>-72128.64</td><td>57279.69</td></tr><tr><th>6</th><td>5</td><td>-41191.34</td><td>-69721.59</td><td>57060.51</td></tr><tr><th>7</th><td>6</td><td>-37702.51</td><td>-69026.13</td><td>62647.24</td></tr><tr><th>8</th><td>7</td><td>-40304.05</td><td>-69744.88</td><td>58881.65</td></tr><tr><th>9</th><td>8</td><td>-43130.85</td><td>-78207.96</td><td>70154.21</td></tr><tr><th>10</th><td>9</td><td>-43709.66</td><td>-74399.43</td><td>61379.54</td></tr></tbody></table>"
      ],
      "text/plain": [
       "10×4 DataFrames.DataFrame\n",
       "│ Row │ Digit │ loglikDirichletMultinomial │ loglikMultinomial │ TestStat │\n",
       "├─────┼───────┼────────────────────────────┼───────────────────┼──────────┤\n",
       "│ 1   │ 0     │ -37358.4                   │ -76611.5          │ 78506.2  │\n",
       "│ 2   │ 1     │ -42179.3                   │ -69330.6          │ 54302.7  │\n",
       "│ 3   │ 2     │ -39985.3                   │ -69257.2          │ 58543.6  │\n",
       "│ 4   │ 3     │ -40519.5                   │ -73718.3          │ 66397.6  │\n",
       "│ 5   │ 4     │ -43488.8                   │ -72128.6          │ 57279.7  │\n",
       "│ 6   │ 5     │ -41191.3                   │ -69721.6          │ 57060.5  │\n",
       "│ 7   │ 6     │ -37702.5                   │ -69026.1          │ 62647.2  │\n",
       "│ 8   │ 7     │ -40304.1                   │ -69744.9          │ 58881.7  │\n",
       "│ 9   │ 8     │ -43130.8                   │ -78208.0          │ 70154.2  │\n",
       "│ 10  │ 9     │ -43709.7                   │ -74399.4          │ 61379.5  │"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a matrix to store log-likelihoods for \n",
    "# subsets of data\n",
    "LogLikmatrix = Matrix(10, 4)\n",
    "\n",
    "for digit in 0:9\n",
    "    iter = 1\n",
    "    digitsets = training[trainingdigits .== digit, :]\n",
    "    X = digitsets[:, findnz(sum(digitsets,1))[2]]\n",
    "    m = size(X, 2)\n",
    "    \n",
    "    # Compute maximum log-likelihood from dirichlet multinomial\n",
    "    LogLikmatrix[digit + 1, 2] = dirmult_newton(X, α0 = ones(m))[1]\n",
    "    \n",
    "    # The MLEs in multinomial are simply the sample proportions\n",
    "    p = sum(X, 1) / sum(X)\n",
    "    p = vec(p)\n",
    "    \n",
    "    LogLikmatrix[digit + 1, 3] = sum(mult_logpdf(X', p))\n",
    "end\n",
    "\n",
    "LogLikmatrix[:, 1] = collect(0:9)\n",
    "\n",
    "# Compute test statistic\n",
    "LogLikmatrix[:, 4] = 2 * (LogLikmatrix[:, 2] - LogLikmatrix[:, 3])\n",
    "\n",
    "DataFrame(Digit = LogLikmatrix[:, 1],\n",
    "    loglikDirichletMultinomial = round(LogLikmatrix[:, 2], 2),\n",
    "loglikMultinomial = round(LogLikmatrix[:, 3], 2),\n",
    "    TestStat = round(LogLikmatrix[:, 4], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test statistics come from a likelihood ratio test comparing the Dirichlet multinomial to the multinomial distribution for each digit $0,\\ldots,9$. Since the multinomial is nested within the Dirichlet multinomial distribution, the likelihood ratio test is valid. The difference in number of parameters is one.\n",
    "\n",
    "Unfortunately, we're testing a parameter on its boundary, so regularity conditions are not satisfied. The null distribution will not be asymptotically $\\chi^2_1$. However, with such large test statistics, it should be safe to conclude the Dirichlet multinomial fits better than multinomial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in test data\n",
    "optdigitstest = readcsv(\"E:/Classes/BiostatisticsM280/Submissions/biostat-m280-JohnShamshoian/HW4/optdigits.tes\")\n",
    "test = Int64.(optdigits[:, 1:64]);\n",
    "testdigits = Int64.(optdigits[:, 65]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9021710698404395"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior = Vector(10)\n",
    "count = 0\n",
    "loglik = Vector(10)\n",
    "N = size(test, 1)\n",
    "for i in 0:9\n",
    "    prior[i + 1] = sum(trainingdigits .== i) / length(trainingdigits)\n",
    "end\n",
    "\n",
    "for i in 1:N\n",
    "    for j in 0:9\n",
    "        testdigitset = test[i, :]\n",
    "        \n",
    "        # Only include those pixel blocks for which an estimate\n",
    "        # was calculated.\n",
    "        # Drop the pixel count if no estimate available\n",
    "        indices = find(mlematrix[:, j + 1])\n",
    "        \n",
    "        # Prior probability * maximum likelihood\n",
    "        loglik[j + 1] = log(prior[j + 1]) + \n",
    "        dirmult_logpdf(testdigitset[indices], mlematrix[:, j + 1][indices])\n",
    "    end\n",
    "    \n",
    "    # Keep track if the classification worked\n",
    "    if (indmax(loglik)) == (testdigits[i] + 1)\n",
    "        count = count + 1\n",
    "    end\n",
    "end\n",
    "\n",
    "correct = count / N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My classifier has an estimated 90.2% accuracy. This could be good or bad depending on the context."
   ]
>>>>>>> 02a17ab1249aa599c4159256cdb2ae8a0bbb95ac
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.1",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
