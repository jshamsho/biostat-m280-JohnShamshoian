{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "John Shamshoian\n",
    "\n",
    "Homework 4\n",
    "\n",
    "## Q1\n",
    "\n",
    "For a multivariate count vector $\\mathbf{x}=(x_1,\\ldots,x_d)$ with batch size $|\\mathbf{x}|=\\sum_{j=1}^d x_j$, show that the probability mass function for Dirichlet-multinomial distribution is\n",
    "$$\n",
    "    f(\\mathbf{x} \\mid \\alpha) \n",
    "\t= \\int_{\\Delta_d} \\binom{|\\mathbf{x}|}{\\mathbf{x}} \\prod_{j=1}^d p_j^{x_j} \\pi(\\mathbf{p}) \\, d \\mathbf{p}  \n",
    "    = \\binom{|\\mathbf{x}|}{\\mathbf{x}} \\frac{\\prod_{j=1}^d \\Gamma(\\alpha_j+x_j)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)} \\frac{\\Gamma(|\\alpha|)}{\\Gamma(|\\alpha|+|\\mathbf{x}|)}\n",
    "$$\n",
    "where $\\Delta_d$ is the unit simplex in $d$ dimensions and $|\\alpha| = \\sum_{j=1}^d \\alpha_j$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $\\mathbf{p} \\sim \\text{Dir}(\\mathbf{\\alpha})$, $\\mathbf{p}$ is a probability density. Therefore \n",
    "\n",
    "$$\n",
    "\\int_{\\Delta_d}\\pi(\\mathbf{p})\\,d\\mathbf{p} =  \\int_{\\Delta_d}\\frac{\\Gamma(|\\alpha|)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)}\\prod_{j=1}^d p_j^{\\alpha_j-1} \\, d\\mathbf{p} = 1\n",
    "$$\n",
    "\n",
    "Rearranging, I get $$\\int_{\\Delta_d}\\prod_{j=1}^d p_j^{\\alpha_j-1}\\,d\\mathbf{p} = \\frac{\\prod_{j=1}^d \\Gamma(\\alpha_j)}{\\Gamma(|\\alpha|)}$$\n",
    "\n",
    "If $\\mathbf{x} \\sim \\text{Multinomial}(\\mathbf{p})$ and $\\mathbf{p} \\sim \\text{Dir}(\\mathbf{\\alpha})$, then $p(\\mathbf{x}\\,|\\,\\mathbf{p},\\mathbf{\\alpha}) = p(\\mathbf{x}\\,|\\,\\mathbf{p})$. Using this fact, I have\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p(\\mathbf{x}, \\mathbf{p}\\,|\\,\\mathbf{\\alpha})&=\\frac{p(\\mathbf{x},\\mathbf{p},\\mathbf{\\alpha})}{p(\\mathbf{\\alpha})}\\cdot\\frac{p(\\mathbf{p},\\mathbf{\\alpha})}{p(\\mathbf{p},\\mathbf{\\alpha})}\\\\\\\\\n",
    "&= p(\\mathbf{x}\\,|\\,\\mathbf{p},\\mathbf{\\alpha})\\cdot p(\\mathbf{p}\\,|\\,\\mathbf{\\alpha})\\\\\\\\\n",
    "&= p(\\mathbf{x}\\,|\\,\\mathbf{p})\\cdot p(\\mathbf{p}\\,|\\,\\mathbf{\\alpha})\\\\\\\\\n",
    "&= \\binom{|\\mathbf{x}|}{\\mathbf{x}} \\prod_{j=1}^d p_j^{x_j} \\frac{\\Gamma(|\\alpha|)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)} \\prod_{j=1}^d p_j^{\\alpha_j-1}\\\\\\\\\n",
    "&= \\binom{|\\mathbf{x}|}{\\mathbf{x}} \\frac{\\Gamma(|\\alpha|)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)} \\prod_{j=1}^d p_j^{x_j + \\alpha_j-1}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "This implies \n",
    "$$\n",
    "\\begin{align}\n",
    "p(\\mathbf{x}\\,|\\,\\mathbf{\\alpha}) &= \\int_{\\Delta_d}p(\\mathbf{x},\\mathbf{p}\\,|\\,\\mathbf{\\alpha})\\,d\\mathbf{p}\\\\\\\\\n",
    "&= \\binom{|\\mathbf{x}|}{\\mathbf{x}} \\frac{\\Gamma(|\\alpha|)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)}\\int_{\\Delta_d}\\prod_{j=1}^d p_j^{x_j + \\alpha_j-1}\\,d\\mathbf{p}\\\\\\\\\n",
    "&= \\binom{|\\mathbf{x}|}{\\mathbf{x}} \\frac{\\Gamma(|\\alpha|)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)}\\frac{\\prod_{j=1}^d \\Gamma(x_j+\\alpha_j)}{\\Gamma(|\\mathbf{x}|+|\\alpha|)}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2\n",
    "\n",
    "The log-likelihood is\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L(\\alpha) &= \\log(p(\\mathbf{x}\\,|\\,\\alpha))\\\\\\\\\n",
    "&=\\log\\bigg[\\binom{|\\mathbf{x}|}{\\mathbf{x}} \\frac{\\Gamma(|\\alpha|)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)}\\frac{\\prod_{j=1}^d \\Gamma(x_j+\\alpha_j)}{\\Gamma(|\\mathbf{x}|+|\\alpha|)}\\bigg]\\\\\\\\\n",
    "&=\\log\\bigg[\\binom{|\\mathbf{x}|}{\\mathbf{x}}\\bigg] + \\log\\bigg[\\frac{\\prod_{j=1}^{d}\\Gamma(x_j+\\alpha_j}{\\prod_{j=1}^{d}\\Gamma(\\alpha_j)}\\bigg] + \\log\\bigg[\\frac{\\Gamma(|\\alpha|)}{\\Gamma(|\\mathbf{x}|+|\\alpha|)}\\bigg]\\\\\\\\\n",
    "&=\\log\\bigg[\\binom{|\\mathbf{x}|}{\\mathbf{x}}\\bigg] + \\sum_{j=1}^{d}\\bigg[\\log\\Gamma(x_j+\\alpha_j)-\\log\\Gamma(\\alpha_j)\\bigg] - \\bigg[\\log\\Gamma(|x|+|\\alpha|)-\\log\\Gamma(|\\alpha|)\\bigg]\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "For indpendent $\\mathbf{x_1}, \\mathbf{x_2},\\ldots,\\mathbf{x_n}$ the log-likelihood becomes \n",
    "\n",
    "$$\\sum_{i=1}^{n}\\log\\bigg[\\binom{|\\mathbf{x_i}|}{\\mathbf{x_i}}\\bigg] + \\sum_{i=1}^{n}\\sum_{j=1}^{d}\\bigg[\\log\\Gamma(x_{ij}+\\alpha_j)-\\log\\Gamma(\\alpha_j)\\bigg] - \\sum_{i=1}^{n}\\bigg[\\log\\Gamma(|\\mathbf{x_i}|+|\\alpha|)-\\log\\Gamma(|\\alpha|)\\bigg]$$\n",
    "\n",
    "\n",
    "The log-likelihood is not concave. I will show the hessian matrix is not always negative definite.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{d^2}{d\\alpha_1^2}L(\\alpha\\,|\\,\\mathbf{x}) = \\psi_1(x_1+\\alpha_1)-\\psi_1(\\alpha_1)-\\psi_1(x_1+x_2+\\alpha_1+\\alpha_2)+\\psi_1(\\alpha_1+\\alpha_2)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Where $\\psi_1$ is the trigamma function.\n",
    "\n",
    "Let $n=1, \\alpha_1 = 10, \\alpha_2=1,x_1=1,x_2=2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021126067017675415"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "α1 = 10\n",
    "α2 = 1\n",
    "x1 = 1\n",
    "x2 = 2\n",
    "trigamma(x1 + α1) - trigamma(α1) \n",
    "- trigamma(x1 + x2 + α1 + α2) + trigamma(α1 + α2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $\\displaystyle\\frac{d^2}{d\\alpha_1^2}L(\\alpha\\,|\\,\\mathbf{x}) > 0$, the diagonal of the hessian is positive. Therefore the hessian is not always negative definite. The log-likelihood is not concave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dirmult_logpdf"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    dirmult_logpdf(x::Vector, α::Vector)\n",
    "    \n",
    "Compute the log-pdf of Dirichlet-multinomial distribution with parameter `α` \n",
    "at data point `x`.\n",
    "\"\"\"\n",
    "function dirmult_logpdf(x::Vector, α::Vector)\n",
    "    s = 0\n",
    "    result = 0\n",
    "    for i in 1:length(x)\n",
    "        #s += x[i]\n",
    "        #result += sum(log(1:s)) - sum(log(1:x[i])) - sum(log(1:(s - x[i])))\n",
    "        result += - lfact(x[i])\n",
    "    end\n",
    "\n",
    "    storage = 0\n",
    "    for i in 1:length(x)\n",
    "        storage += lgamma(x[i] + α[i]) - lgamma(α[i])\n",
    "    end\n",
    "    #print(lgamma(α[1]))\n",
    "    return result + storage - lgamma(sum(α) + sum(x)) + lgamma(sum(α)) + lfact(sum(x))\n",
    "end\n",
    "\n",
    "function dirmult_logpdf!(r::Vector, X::Matrix, α::Vector)\n",
    "    for j in 1:size(X, 2)\n",
    "        r[j] = dirmult_logpdf(X[:, j], α)\n",
    "    end\n",
    "    return r\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    dirmult_logpdf(X, α)\n",
    "    \n",
    "Compute the log-pdf of Dirichlet-multinomial distribution with parameter `α` \n",
    "at each data point in `X`. Each column of `X` is one data point.\n",
    "\"\"\"\n",
    "function dirmult_logpdf(X::Matrix, α::Vector)\n",
    "    r = zeros(size(X, 2))\n",
    "    dirmult_logpdf!(r, X, α)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optdigits = readcsv(\"E:/Classes/BiostatisticsM280/Submissions/biostat-m280-JohnShamshoian/HW4/optdigits.tra\")\n",
    "training = Int64.(optdigits[:, 1:64]);\n",
    "digits = Int64.(optdigits[:, 65]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3823-element Array{Float64,1}:\n",
       " -165.188\n",
       " -176.23 \n",
       " -167.774\n",
       " -165.564\n",
       " -157.79 \n",
       " -176.071\n",
       " -158.423\n",
       " -159.258\n",
       " -174.302\n",
       " -178.407\n",
       " -171.294\n",
       " -169.383\n",
       " -175.753\n",
       "    ⋮    \n",
       " -160.49 \n",
       " -158.633\n",
       " -156.935\n",
       " -171.975\n",
       " -177.638\n",
       " -169.735\n",
       " -158.423\n",
       " -159.465\n",
       " -159.877\n",
       " -169.735\n",
       " -173.149\n",
       " -155.411"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirmult_logpdf(training', [1; ones(Int64, 63)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5\n",
    "\n",
    "The score function is $\\nabla L(\\alpha) = \\displaystyle\\frac{d}{d\\mathbf{\\alpha}}L(\\alpha)$, where \n",
    "\n",
    "$$\\displaystyle\\frac{d}{d\\alpha_j}L(\\alpha)=\\sum_{i=1}^{n}\\bigg[\\psi(x_{ij} + \\alpha_j)-\\psi(\\alpha_j)\\bigg]-\\sum_{i=1}^{n}\\bigg[\\psi(|\\mathbf{x_i}| + |\\alpha|)-\\psi(|\\alpha|)\\bigg]$$\n",
    "\n",
    "$\\psi$ is the digamma function.\n",
    "\n",
    "The observed information is $-d^{2}L(\\alpha)$, where\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\big[-d^{2}L(\\alpha))\\big]_{kj} &= -\\frac{d}{d\\alpha_k\\alpha_j}L(\\alpha)\\\\\\\\\n",
    "&=\\begin{cases}\n",
    "  \\displaystyle\\sum_{i=1}^{n}\\bigg[\\psi_{1}(|\\mathbf{x_i}|+|\\alpha|) - \\psi_1(|\\alpha|)\\bigg]-\\displaystyle\\sum_{i=1}^{n}\\bigg[\\psi_{1}(x_{ij}+\\alpha_j)-\\psi_1(\\alpha_j)\\bigg] & \\text{if }k = j\\\\\\\\\n",
    " \\displaystyle\\sum_{i=1}^{n}\\bigg[\\psi_{1}(|\\mathbf{x_i}|+|\\alpha|) - \\psi_1(|\\alpha|)\\bigg] & \\text{if }k\\neq j\n",
    "\\end{cases}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "To derive the expected information matrix $\\mathbb{E}[-d^{2}L(\\alpha)]$ I will use the alternate form of the log-likelihood from homework 5.\n",
    "\n",
    "$$\n",
    "L(\\alpha) = \\sum_{i=1}^{n}\\ln\\binom{|\\mathbf{x_i}|}{\\mathbf{x_i}} + \\sum_{i=1}^{n}\\sum_{j=1}^{d}\\sum_{k=0}^{x_{ij}-1}\\ln(\\alpha_j+k)-\\sum_{i=1}^{n}\\sum_{k=0}^{|\\mathbf{x_i}|-1}\\ln(|\\alpha|+k)\n",
    "$$\n",
    "\n",
    "For $k\\neq j$,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}[-d^{2}L(\\alpha)]_{kj} &=- \\sum_{i=1}^{n}\\sum_{x_{i1},\\ldots,x_{id}}^{|\\mathbf{x_i}|}\\sum_{k=0}^{|\\mathbf{x_i}|-1}\\frac{1}{(|\\alpha|+k)^2}p(\\mathbf{x_i})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "And for $k=j$,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}[-d^{2}L(\\alpha)]_{kj}=\\sum_{i=1}^{n}\\sum_{x_{i1}\\ldots,x_{id}}^{|\\mathbf{x_i}|}\\sum_{k=0}^{x_{ij}-1}\\frac{1}{(\\alpha_{j}+k)^2}p(\\mathbf{x_i})-\\sum_{i=1}^{n}\\sum_{x_{i1}\\ldots,x_{id}}^{|\\mathbf{x_i}|}\\sum_{k=0}^{|\\mathbf{x_i}|-1}\\frac{1}{(|\\alpha|+k)^2}p(\\mathbf{x_i})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Fisher scoring is inefficient because the triple summation would take a while to compute for each iteration of the newton-raphson algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6\n",
    "\n",
    "The observed information matrix has the structure $D+11'c$, where $D$ is a $d\\times d$ diagonal matrix with positive entries, $c$ is a negative constant, and $1$ is a $d\\times 1$ vector of ones.\n",
    "\n",
    "$D+11'c$ is positive definite if and only if $(D+11'c)^{-1} = D^{-1} - c\\displaystyle\\frac{D^{-1}11'D^{-1}}{1+c1'D^{-1}1}$ is positive definite.\n",
    "\n",
    "From this expression I see that if $1+c1'D^{-1}1 > 0$, then $(D+11'c)^{-1}$ is positive definite.\n",
    "\n",
    "If $1+c1'D^{-1}1 \\leq 0$, replace $c$ with $-.95\\frac{1}{1'D^{-1}1}$\n",
    "\n",
    "Since this adjustment guarantees $(D+11'c)^{-1}$ is positive definite, this adjustment guarantees $D + 11'c$ is positive definite as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7\n",
    "\n",
    "In the context of Q1, the multinomial probabilities $\\mathbf{p} = (p_1,\\ldots,p_{d-1})$ are random variables with $\\mathbb{E}[p_i] = \\displaystyle\\frac{\\alpha_i}{|\\alpha|}$ and $Var(p_i) = \\displaystyle\\frac{\\alpha_i(|\\alpha| - \\alpha_i)}{|\\alpha|^2(|\\alpha| +1)}$.\n",
    "\n",
    "Also $\\mathbb{E}(x_i) = \\mathbf{x}\\displaystyle\\frac{\\alpha_i}{|\\alpha|}$ and $Var(X_i) = |\\mathbf{x}|\\displaystyle\\frac{\\alpha_i}{|\\alpha|}\\bigg(1-\\frac{\\alpha_i}{|\\alpha|}\\bigg)\\bigg(\\frac{|\\mathbf{x}|+|\\alpha|}{1+|\\alpha|}\\bigg) = |\\mathbf{x}|\\,\\mathbb{E}[p_i](1-\\mathbb{E}[p_i])\\bigg(\\frac{|\\mathbf{x}|+|\\alpha|}{1+|\\alpha|}\\bigg)$\n",
    "\n",
    "Another result is $Cov(X_i,X_j) = -\\displaystyle\\frac{|\\mathbf{x}|\\alpha_i\\alpha_j(|\\mathbf{x}| + |\\alpha|)}{|\\alpha|^2(1+|\\alpha|)} = -\\mathbb{E}[p_i]\\mathbb{E}[p_j]\\bigg(\\frac{|\\mathbf{x}|+|\\alpha|}{1+|\\alpha|}\\bigg)$\n",
    "\n",
    "Comparing with the multinomial distribution: If $(x_1,\\ldots,x_{d-1}) \\sim M(p_1,\\ldots,p_{d-1})$, $Var(X_i) = |\\mathbf{x}|p_i(1-p_i)$ and $Cov(x_i,x_j) = -|\\mathbf{x}|p_ip_j$\n",
    "\n",
    "It follows that $\\Sigma_{DM} = \\displaystyle\\bigg[\\frac{|\\mathbf{x}+|\\alpha|}{1+|\\alpha|}\\bigg]\\Sigma_M = C\\Sigma_M$, where $\\Sigma_{DM}$ is the covariance matrix of $\\mathbf{x}$ treating $\\mathbf{x}$ as dirichlet multinomial and $\\Sigma_M$ is the sample covariance matrix of $\\mathbf{x}$ treating $\\mathbf{x}$ as multinomial.\n",
    "\n",
    "So, $p_j$ can be estimated by $\\displaystyle\\frac{\\sum_{i=1}^{n}x_{ij}}{\\sum_{i=1}^{n}|\\mathbf{x_i}|}$ and $\\Sigma_{DM}$ can be estimated by $\\displaystyle\\frac{1}{n-1}\\sum_{i=1}^{N}(\\mathbf{x}_i-\\overline{\\mathbf{x}})(\\mathbf{x}_i-\\overline{\\mathbf{x}})^{T}$\n",
    "\n",
    "Solving for $C$, $\\hat{C} = \\displaystyle\\bigg(\\frac{|\\hat{\\Sigma}_{DM}|}{|\\hat{\\Sigma}_{M}|}\\bigg)^{1/(k-1)}$\n",
    "\n",
    "Since $\\mathbb{E}(x_i) = \\mathbf{x_i}\\displaystyle\\frac{\\alpha_i}{|\\alpha|}$, we have $\\mathbb{E}[|\\mathbf{\\overline{x}}_i|] = \\displaystyle\\frac{\\alpha_1}{|\\alpha|}\\sum_{i=1}^{n}|\\mathbf{x}_i|/n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition dirmult_newton(Array{T<:Any, 2}) in module Main at In[886]:26 overwritten at In[895]:26.\n",
      "WARNING: Method definition #dirmult_newton(Array{Any, 1}, Main.#dirmult_newton, Array{T<:Any, 2}) in module Main overwritten.\n",
      "\u001b[1m\u001b[31mWARNING: replacing docs for 'dirmult_newton :: Tuple{Array{T,2}}' in module 'Main'.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dirmult_newton"
      ]
     },
     "execution_count": 895,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    dirmult_newton(X)\n",
    "\n",
    "Find the MLE of Dirichlet-multinomial distribution using Newton's method.\n",
    "\n",
    "# Argument\n",
    "* `X`: an `n`-by-`d` matrix of counts; each column is one data point.\n",
    "\n",
    "# Optional argument  \n",
    "* `alpha0`: a `d` vector of starting point (optional). \n",
    "* `maxiters`: the maximum allowable Newton iterations (default 100). \n",
    "* `tolfun`: the tolerance for  relative change in objective values (default 1e-6). \n",
    "\n",
    "# Output\n",
    "* `maximum`: the log-likelihood at MLE.   \n",
    "* `estimate`: the MLE. \n",
    "* `gradient`: the gradient at MLE. \n",
    "* `hessian`: the Hessian at MLE. \n",
    "* `se`: a `d` vector of standard errors. \n",
    "* `iterations`: the number of iterations performed.\n",
    "\"\"\"\n",
    "function dirmult_newton(X::Matrix; α0::Vector = nothing, \n",
    "            maxiters::Int = 100, tolfun::Float64 = 1e-6)\n",
    "    \n",
    "    # Retain only columns with non-zero sum. Skipping this step will make the hessian singular.\n",
    "    X = X[:, findnz(sum(X,1))[2]]\n",
    "    \n",
    "    c = 0.0\n",
    "    n, m = size(X)\n",
    "    # set default starting point from Q7\n",
    "    α0 = ones(size(X)[2])\n",
    "    \n",
    "    # Initialize gradient vector\n",
    "    gradient = zeros(m)\n",
    "    \n",
    "    # Initialize diagonal from Q6 notation\n",
    "    D = Diagonal(zeros(m))\n",
    "    \n",
    "    # Initialize hessian\n",
    "    H = Array(Float64, m, m)\n",
    "    \n",
    "    # Compute initial log-likelihood\n",
    "    loglold = sum(dirmult_logpdf(X',α0))\n",
    "    \n",
    "    # Initialize variable to store new log-likelihood\n",
    "    logl = loglold\n",
    "    counter = 0\n",
    "    #tolfun = 1e-6\n",
    "    \n",
    "    # Initialize stepsize\n",
    "    stepsize = 1\n",
    "    \n",
    "    # Initialize αtry vector. This will be used in selecting a good stepsize in line search\n",
    "    αtry = zeros(m)\n",
    "    \n",
    "    # Initialize vector of ones\n",
    "    z = ones(m)\n",
    "    logltry = Float64\n",
    "    itercount = 0\n",
    "    \n",
    "    # Newton loop\n",
    "    for iter in 1:maxiters\n",
    "        \n",
    "        loglold = logl\n",
    "        \n",
    "        # Compute gradient as in Q5\n",
    "        for j in 1:n\n",
    "            for i in 1:m\n",
    "                gradient[i] = gradient[i] + digamma(X[j,i] + α0[i]) - digamma(α0[i]) - digamma(sum(X[j, :]) + sum(α0)) + digamma(sum(α0))\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        # approximated observed information matrix\n",
    "        \n",
    "        # Compute c as in Q6\n",
    "        for j in 1:n\n",
    "            c = c + trigamma(sum(X[j, :]) + sum(α0))\n",
    "        end\n",
    "        \n",
    "        c = c - n * trigamma(sum(α0))\n",
    "        \n",
    "        # Compute D as in Q6\n",
    "        for i = 1:m\n",
    "            for j in 1:n   \n",
    "                D[i,i] = D[i,i] - trigamma(α0[i] + X[j,i]) \n",
    "            end\n",
    "            D[i, i] = D[i, i] + n * trigamma(α0[i]) \n",
    "        end\n",
    "        \n",
    "        # Check if negative hessian is positive definite\n",
    "        # If not pd, overwrite c to make it pd\n",
    "        if (1 + c * dot(z, inv(D) * z)) <= 0\n",
    "            c = -.95 * 1 / dot(z, inv(D) * z)\n",
    "        end\n",
    "            \n",
    "        # This is the negative of the hessian\n",
    "        # It's positive definite\n",
    "        H = D + ones(m) * ones(m)' * c\n",
    "        \n",
    "        # line search loop\n",
    "        for lsiter in 1:10\n",
    "            s = (2.0)^(- 2 * lsiter + 2)\n",
    "                \n",
    "            # Let's see if this αtry is a good update\n",
    "            αtry = α0 + inv(H) * gradient * s\n",
    "            logltry = sum(dirmult_logpdf(X',αtry))\n",
    "            \n",
    "            # If αtry is a good update, keep it\n",
    "            if (logltry > logl) & (minimum(αtry) > 0)\n",
    "                stepsize = s\n",
    "                break;\n",
    "            end\n",
    "        end\n",
    "    \n",
    "        # compute Newton's direction\n",
    "        α0 = α0 + inv(H) * gradient * stepsize\n",
    "        logl = sum(dirmult_logpdf(X', α0))\n",
    "        \n",
    "        # Check convergence criteria\n",
    "        if abs(logl - loglold) < (tolfun * (abs(loglold) + 1))\n",
    "            #print(\"converged\")\n",
    "            break;\n",
    "        end\n",
    "        \n",
    "        # If it convergence criteria is not reached, overwrite loglold and start again\n",
    "        # Overwrite gradient, negative hessian, and diagonal\n",
    "        for i in 1:m\n",
    "            gradient[i] = 0.0\n",
    "            H[i, i] = 0.0\n",
    "            D[i, i] = 0.0\n",
    "        end\n",
    "        \n",
    "        itercount += 1\n",
    "        \n",
    "    end\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return logl, α0, gradient, - H, sqrt(diag(H)), itercount  \n",
    "\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.167628646319555"
      ]
     },
     "execution_count": 911,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dirmult_newton(X, α0 = ones(m))[2][4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48-element Array{Float64,1}:\n",
       "  0.0374573\n",
       "  4.9944   \n",
       " 14.9002   \n",
       " 12.1676   \n",
       "  2.45644  \n",
       "  0.063539 \n",
       "  1.02392  \n",
       " 14.6018   \n",
       " 14.7624   \n",
       " 13.749    \n",
       " 11.9442   \n",
       "  0.545983 \n",
       "  4.16774  \n",
       "  ⋮        \n",
       "  0.735115 \n",
       " 14.8423   \n",
       " 11.8115   \n",
       " 11.7306   \n",
       " 15.2444   \n",
       "  2.5917   \n",
       "  0.0207704\n",
       "  5.0277   \n",
       " 15.3815   \n",
       " 15.0797   \n",
       "  5.82498  \n",
       "  0.194466 "
      ]
     },
     "execution_count": 1015,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    iter = 1\n",
    "    digitsets = training[digits .== digit, :]\n",
    "    X = digitsets[:, findnz(sum(digitsets,1))[2]]\n",
    "    currentmle = dirmult_newton(X, α0 = ones(m))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlematrix = Matrix(64,10)\n",
    "for digit in 0:9\n",
    "    iter = 1\n",
    "    digitsets = training[digits .== digit, :]\n",
    "    X = digitsets[:, findnz(sum(digitsets,1))[2]]\n",
    "    currentmle = dirmult_newton(X, α0 = ones(m))[2]\n",
    "    for i in 1:64\n",
    "        if in(i, findnz(sum(digitsets, 1))[2])\n",
    "            mlematrix[i, digit + 1] = currentmle[iter]\n",
    "            iter += 1\n",
    "        else\n",
    "            mlematrix[i, digit + 1] = \".\"\n",
    "        end\n",
    "        \n",
    "    end\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mINFO: Recompiling stale cache file C:\\Users\\John\\.julia\\lib\\v0.5\\StatsBase.ji for module StatsBase.\n",
      "\u001b[0m\u001b[1m\u001b[34mINFO: Recompiling stale cache file C:\\Users\\John\\.julia\\lib\\v0.5\\DataArrays.ji for module DataArrays.\n",
      "\u001b[0mWARNING: StatsBase.WeightVec is deprecated, use StatsBase.Weights instead.\n",
      "  likely near C:\\Users\\John\\.julia\\v0.5\\DataArrays\\src\\reduce.jl:178\n",
      "WARNING: StatsBase.WeightVec is deprecated, use StatsBase.Weights instead.\n",
      "  likely near C:\\Users\\John\\.julia\\v0.5\\DataArrays\\src\\reduce.jl:178\n",
      "WARNING: StatsBase.WeightVec is deprecated, use StatsBase.Weights instead.\n",
      "  likely near C:\\Users\\John\\.julia\\v0.5\\DataArrays\\src\\reduce.jl:178\n",
      "WARNING: StatsBase.WeightVec is deprecated, use StatsBase.Weights instead.\n",
      "  likely near C:\\Users\\John\\.julia\\v0.5\\DataArrays\\src\\reduce.jl:187\n",
      "WARNING: StatsBase.WeightVec is deprecated, use StatsBase.Weights instead.\n",
      "  likely near C:\\Users\\John\\.julia\\v0.5\\DataArrays\\src\\reduce.jl:187\n",
      "WARNING: StatsBase.WeightVec is deprecated, use StatsBase.Weights instead.\n",
      "  likely near C:\\Users\\John\\.julia\\v0.5\\DataArrays\\src\\reduce.jl:187\n",
      "WARNING: StatsBase.WeightVec is deprecated, use StatsBase.Weights instead.\n",
      "  likely near C:\\Users\\John\\.julia\\v0.5\\DataArrays\\src\\extras.jl:8\n",
      "WARNING: StatsBase.WeightVec is deprecated, use StatsBase.Weights instead.\n",
      "  likely near C:\\Users\\John\\.julia\\v0.5\\DataArrays\\src\\extras.jl:26\n",
      "\u001b[1m\u001b[34mINFO: Recompiling stale cache file C:\\Users\\John\\.julia\\lib\\v0.5\\DataFrames.ji for module DataFrames.\n",
      "\u001b[0mWARNING: Method definition describe(AbstractArray) in module StatsBase at C:\\Users\\John\\.julia\\v0.5\\StatsBase\\src\\scalarstats.jl:573 overwritten in module DataFrames at C:\\Users\\John\\.julia\\v0.5\\DataFrames\\src\\abstractdataframe\\abstractdataframe.jl:407.\n",
      "WARNING: Method definition describe(AbstractArray) in module StatsBase at C:\\Users\\John\\.julia\\v0.5\\StatsBase\\src\\scalarstats.jl:573 overwritten in module DataFrames at C:\\Users\\John\\.julia\\v0.5\\DataFrames\\src\\abstractdataframe\\abstractdataframe.jl:407.\n"
     ]
    }
   ],
   "source": [
    "using DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame(digit0=mlematrix[:,1],digit1=mlematrix[:,2]) = 64×2 DataFrames.DataFrame\n",
      "│ Row │ digit0    │ digit1     │\n",
      "├─────┼───────────┼────────────┤\n",
      "│ 1   │ \".\"       │ \".\"        │\n",
      "│ 2   │ 0.0374573 │ 0.00804469 │\n",
      "│ 3   │ 4.9944    │ 0.515717   │\n",
      "│ 4   │ 14.9002   │ 2.10717    │\n",
      "│ 5   │ 12.1676   │ 3.06881    │\n",
      "│ 6   │ 2.45644   │ 1.32609    │\n",
      "│ 7   │ 0.063539  │ 0.138135   │\n",
      "│ 8   │ \".\"       │ \".\"        │\n",
      "│ 9   │ \".\"       │ \".\"        │\n",
      "│ 10  │ 1.02392   │ 0.0574206  │\n",
      "│ 11  │ 14.6018   │ 1.04456    │\n",
      "│ 12  │ 14.7624   │ 3.25332    │\n",
      "│ 13  │ 13.749    │ 4.1212     │\n",
      "│ 14  │ 11.9442   │ 2.23572    │\n",
      "│ 15  │ 0.545983  │ 0.179765   │\n",
      "│ 16  │ \".\"       │ \".\"        │\n",
      "│ 17  │ \".\"       │ 0.0064881  │\n",
      "│ 18  │ 4.16774   │ 0.240368   │\n",
      "│ 19  │ 16.2704   │ 1.92753    │\n",
      "│ 20  │ 4.54193   │ 4.09961    │\n",
      "│ 21  │ 2.57487   │ 4.18178    │\n",
      "│ 22  │ 14.3986   │ 1.86153    │\n",
      "│ 23  │ 3.57687   │ 0.107329   │\n",
      "│ 24  │ \".\"       │ \".\"        │\n",
      "│ 25  │ \".\"       │ 0.00642547 │\n",
      "│ 26  │ 5.91943   │ 0.512601   │\n",
      "│ 27  │ 14.3909   │ 2.60559    │\n",
      "│ 28  │ 1.20934   │ 4.09069    │\n",
      "│ 29  │ 0.15378   │ 4.11431    │\n",
      "│ 30  │ 10.3271   │ 1.68213    │\n",
      "│ 31  │ 7.62962   │ 0.0917629  │\n",
      "│ 32  │ \".\"       │ \".\"        │\n",
      "│ 33  │ \".\"       │ \".\"        │\n",
      "│ 34  │ 6.16451   │ 0.346525   │\n",
      "│ 35  │ 13.4568   │ 1.65972    │\n",
      "│ 36  │ 0.501628  │ 3.09335    │\n",
      "│ 37  │ 0.107409  │ 4.04602    │\n",
      "│ 38  │ 9.70471   │ 1.62695    │\n",
      "│ 39  │ 8.48959   │ 0.0785703  │\n",
      "│ 40  │ \".\"       │ \".\"        │\n",
      "│ 41  │ \".\"       │ \".\"        │\n",
      "│ 42  │ 3.65217   │ 0.104908   │\n",
      "│ 43  │ 15.3508   │ 0.823955   │\n",
      "│ 44  │ 1.40097   │ 2.46289    │\n",
      "│ 45  │ 1.09271   │ 3.95088    │\n",
      "│ 46  │ 12.7183   │ 1.75996    │\n",
      "│ 47  │ 7.14006   │ 0.101055   │\n",
      "│ 48  │ \".\"       │ \".\"        │\n",
      "│ 49  │ \".\"       │ \".\"        │\n",
      "│ 50  │ 0.735115  │ 0.0364109  │\n",
      "│ 51  │ 14.8423   │ 0.812557   │\n",
      "│ 52  │ 11.8115   │ 2.65503    │\n",
      "│ 53  │ 11.7306   │ 4.06548    │\n",
      "│ 54  │ 15.2444   │ 2.28228    │\n",
      "│ 55  │ 2.5917    │ 0.273678   │\n",
      "│ 56  │ \".\"       │ 0.0303988  │\n",
      "│ 57  │ \".\"       │ \".\"        │\n",
      "│ 58  │ 0.0207704 │ 0.0177825  │\n",
      "│ 59  │ 5.0277    │ 0.516286   │\n",
      "│ 60  │ 15.3815   │ 2.02704    │\n",
      "│ 61  │ 15.0797   │ 3.53656    │\n",
      "│ 62  │ 5.82498   │ 2.21698    │\n",
      "│ 63  │ 0.194466  │ 0.409664   │\n",
      "│ 64  │ \".\"       │ 0.0420303  │\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>digit0</th><th>digit1</th></tr></thead><tbody><tr><th>1</th><td>.</td><td>.</td></tr><tr><th>2</th><td>0.03745725423383036</td><td>0.008044693396562703</td></tr><tr><th>3</th><td>4.994396356888004</td><td>0.5157165448315822</td></tr><tr><th>4</th><td>14.900232346391284</td><td>2.1071666722417675</td></tr><tr><th>5</th><td>12.167628646319555</td><td>3.068808530932073</td></tr><tr><th>6</th><td>2.4564449300815174</td><td>1.3260886463875132</td></tr><tr><th>7</th><td>0.06353898125232418</td><td>0.13813499745609933</td></tr><tr><th>8</th><td>.</td><td>.</td></tr><tr><th>9</th><td>.</td><td>.</td></tr><tr><th>10</th><td>1.0239177165880355</td><td>0.05742063025342625</td></tr><tr><th>11</th><td>14.601771256925662</td><td>1.0445603410008097</td></tr><tr><th>12</th><td>14.76242229378527</td><td>3.2533165222410565</td></tr><tr><th>13</th><td>13.749013039288764</td><td>4.1212046379860405</td></tr><tr><th>14</th><td>11.944156810691666</td><td>2.2357236987986697</td></tr><tr><th>15</th><td>0.5459828428149237</td><td>0.17976495678630755</td></tr><tr><th>16</th><td>.</td><td>.</td></tr><tr><th>17</th><td>.</td><td>0.0064880959950409</td></tr><tr><th>18</th><td>4.167741502167346</td><td>0.2403681137475733</td></tr><tr><th>19</th><td>16.270376431388524</td><td>1.92753196136842</td></tr><tr><th>20</th><td>4.5419302677511695</td><td>4.099606434143458</td></tr><tr><th>21</th><td>2.5748682278668547</td><td>4.181779304286183</td></tr><tr><th>22</th><td>14.398582252561017</td><td>1.8615282819280572</td></tr><tr><th>23</th><td>3.576865895453129</td><td>0.10732872473079842</td></tr><tr><th>24</th><td>.</td><td>.</td></tr><tr><th>25</th><td>.</td><td>0.006425470246886345</td></tr><tr><th>26</th><td>5.919431659774412</td><td>0.5126012727768411</td></tr><tr><th>27</th><td>14.39089406213258</td><td>2.6055897620991164</td></tr><tr><th>28</th><td>1.20933818564042</td><td>4.090693374393191</td></tr><tr><th>29</th><td>0.15378047234886325</td><td>4.114310488769563</td></tr><tr><th>30</th><td>10.327149190297678</td><td>1.6821268702461938</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/plain": [
       "64×2 DataFrames.DataFrame\n",
       "│ Row │ digit0    │ digit1     │\n",
       "├─────┼───────────┼────────────┤\n",
       "│ 1   │ \".\"       │ \".\"        │\n",
       "│ 2   │ 0.0374573 │ 0.00804469 │\n",
       "│ 3   │ 4.9944    │ 0.515717   │\n",
       "│ 4   │ 14.9002   │ 2.10717    │\n",
       "│ 5   │ 12.1676   │ 3.06881    │\n",
       "│ 6   │ 2.45644   │ 1.32609    │\n",
       "│ 7   │ 0.063539  │ 0.138135   │\n",
       "│ 8   │ \".\"       │ \".\"        │\n",
       "│ 9   │ \".\"       │ \".\"        │\n",
       "│ 10  │ 1.02392   │ 0.0574206  │\n",
       "│ 11  │ 14.6018   │ 1.04456    │\n",
       "⋮\n",
       "│ 53  │ 11.7306   │ 4.06548    │\n",
       "│ 54  │ 15.2444   │ 2.28228    │\n",
       "│ 55  │ 2.5917    │ 0.273678   │\n",
       "│ 56  │ \".\"       │ 0.0303988  │\n",
       "│ 57  │ \".\"       │ \".\"        │\n",
       "│ 58  │ 0.0207704 │ 0.0177825  │\n",
       "│ 59  │ 5.0277    │ 0.516286   │\n",
       "│ 60  │ 15.3815   │ 2.02704    │\n",
       "│ 61  │ 15.0797   │ 3.53656    │\n",
       "│ 62  │ 5.82498   │ 2.21698    │\n",
       "│ 63  │ 0.194466  │ 0.409664   │\n",
       "│ 64  │ \".\"       │ 0.0420303  │"
      ]
     },
     "execution_count": 1025,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show DataFrame(digit0 = mlematrix[:, 1], digit1 = mlematrix[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function mult_logpdf!(r::Vector, X::Matrix, p::Vector)\n",
    "    for j in 1:size(X, 2)\n",
    "        d = Multinomial(sum(X[:, j]), p)\n",
    "        r[j] = logpdf(d, X[j, :])\n",
    "    end\n",
    "    return r\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    mult_logpdf(X, α)\n",
    "    \n",
    "Compute the log-pdf of multinomial distribution with parameter `p` \n",
    "at each data point in `X`. Each column of `X` is one data point.\n",
    "\"\"\"\n",
    "function mult_logpdf(X::Matrix, p::Vector)\n",
    "    r = zeros(size(X, 2))\n",
    "    dirmult_logpdf!(r, X, p)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>Digit</th><th>loglikDirichletMultinomial</th><th>loglikMultinomial</th><th>TestStat</th></tr></thead><tbody><tr><th>1</th><td>0</td><td>-37358.43</td><td>-76611.51</td><td>78506.16</td></tr><tr><th>2</th><td>1</td><td>-42179.3</td><td>-69330.65</td><td>54302.7</td></tr><tr><th>3</th><td>2</td><td>-39985.35</td><td>-69257.17</td><td>58543.64</td></tr><tr><th>4</th><td>3</td><td>-40519.47</td><td>-73718.29</td><td>66397.63</td></tr><tr><th>5</th><td>4</td><td>-43488.79</td><td>-72128.64</td><td>57279.7</td></tr><tr><th>6</th><td>5</td><td>-41191.67</td><td>-69721.59</td><td>57059.84</td></tr><tr><th>7</th><td>6</td><td>-37702.51</td><td>-69026.13</td><td>62647.24</td></tr><tr><th>8</th><td>7</td><td>-40304.04</td><td>-69744.88</td><td>58881.68</td></tr><tr><th>9</th><td>8</td><td>-43130.85</td><td>-78207.96</td><td>70154.21</td></tr><tr><th>10</th><td>9</td><td>-43709.7</td><td>-74399.43</td><td>61379.45</td></tr></tbody></table>"
      ],
      "text/plain": [
       "10×4 DataFrames.DataFrame\n",
       "│ Row │ Digit │ loglikDirichletMultinomial │ loglikMultinomial │ TestStat │\n",
       "├─────┼───────┼────────────────────────────┼───────────────────┼──────────┤\n",
       "│ 1   │ 0     │ -37358.4                   │ -76611.5          │ 78506.2  │\n",
       "│ 2   │ 1     │ -42179.3                   │ -69330.6          │ 54302.7  │\n",
       "│ 3   │ 2     │ -39985.3                   │ -69257.2          │ 58543.6  │\n",
       "│ 4   │ 3     │ -40519.5                   │ -73718.3          │ 66397.6  │\n",
       "│ 5   │ 4     │ -43488.8                   │ -72128.6          │ 57279.7  │\n",
       "│ 6   │ 5     │ -41191.7                   │ -69721.6          │ 57059.8  │\n",
       "│ 7   │ 6     │ -37702.5                   │ -69026.1          │ 62647.2  │\n",
       "│ 8   │ 7     │ -40304.0                   │ -69744.9          │ 58881.7  │\n",
       "│ 9   │ 8     │ -43130.8                   │ -78208.0          │ 70154.2  │\n",
       "│ 10  │ 9     │ -43709.7                   │ -74399.4          │ 61379.4  │"
      ]
     },
     "execution_count": 1107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogLikmatrix = Matrix(10,4)\n",
    "for digit in 0:9\n",
    "    iter = 1\n",
    "    digitsets = training[digits .== digit, :]\n",
    "    X = digitsets[:, findnz(sum(digitsets,1))[2]]\n",
    "    LogLikmatrix[digit + 1, 2] = dirmult_newton(X, α0 = ones(m))[1]\n",
    "    \n",
    "    p = sum(X, 1) / sum(X)\n",
    "    p = vec(p)\n",
    "    \n",
    "    LogLikmatrix[digit + 1, 3] = sum(mult_logpdf(X', p))\n",
    "end\n",
    "\n",
    "LogLikmatrix[:, 1] = collect(0:9)\n",
    "LogLikmatrix[:, 4] = 2 * (LogLikmatrix[:, 2] - LogLikmatrix[:, 3])\n",
    "\n",
    "DataFrame(Digit = LogLikmatrix[:, 1], loglikDirichletMultinomial = round(LogLikmatrix[:, 2], 2),\n",
    "loglikMultinomial = round(LogLikmatrix[:, 3], 2), TestStat = round(LogLikmatrix[:, 4], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "BoundsError: attempt to access 52-element Array{Float64,1} at index [53]",
     "output_type": "error",
     "traceback": [
      "BoundsError: attempt to access 52-element Array{Float64,1} at index [53]",
      "",
      " in dirmult_logpdf(::Array{Int64,1}, ::Array{Float64,1}) at .\\In[3]:18",
      " in dirmult_logpdf!(::Array{Float64,1}, ::Array{Int64,2}, ::Array{Float64,1}) at .\\In[3]:26",
      " in dirmult_logpdf(::Array{Int64,2}, ::Array{Float64,1}) at .\\In[3]:39"
     ]
    }
   ],
   "source": [
    "optdigitstest = readcsv(\"E:/Classes/BiostatisticsM280/Submissions/biostat-m280-JohnShamshoian/HW4/optdigits.tes\")\n",
    "test = Int64.(optdigits[:, 1:64]);\n",
    "testdigits = Int64.(optdigits[:, 65]);\n",
    "digitk = test[testdigits .== 4, :]\n",
    "Xtest = digitk[:, findnz(sum(digitk,1))[2]]\n",
    "digitk = training[digits .== 1, :]\n",
    "X = digitk[:, findnz(sum(digitk,1))[2]]\n",
    "sum(dirmult_logpdf(Xtest', dirmult_newton(X, α0 = ones(m))[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48×48 Array{Float64,2}:\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  …  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  …  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  …  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " ⋮                        ⋮              ⋱                      ⋮            \n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  …  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  …  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0"
      ]
     },
     "execution_count": 1110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    digitk = training[digits .== 0, :]\n",
    "X = digitk[:, findnz(sum(digitk,1))[2]]\n",
    "#X = training[:, findnz(sum(training,1))[2]]\n",
    "    #X = [1 2 3; 2 2 4; 1 3 5; 3 1 4]\n",
    "    #X = [collect(1:10) collect(5:14) collect(10:19)]\n",
    "    c = 0\n",
    "    n, m = size(X)\n",
    "    # set default starting point from Q7\n",
    "    α0 = ones(size(X)[2])\n",
    "    gradient = zeros(m)\n",
    "    D = Diagonal(zeros(m))\n",
    "    H = Array(Float64, m, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "hi1\n",
      "hi2\n",
      "hi3\n",
      "hi4\n",
      "hi5\n",
      "hi6\n",
      "hi7\n",
      "hi8\n",
      "hi9\n",
      "hi10\n",
      "hi11\n",
      "hi12\n",
      "hi13\n",
      "hi14\n",
      "hiconverged"
     ]
    }
   ],
   "source": [
    "loglold = sum(dirmult_logpdf(X',α0))\n",
    "logl = loglold\n",
    "counter = 0\n",
    "tolfun = 1e-6\n",
    "stepsize = 1\n",
    "αtemp = zeros(m)\n",
    "Z = ones(m)\n",
    "for iter in 1:100\n",
    "    loglold = logl\n",
    "    \n",
    "   #D = Diagonal(zeros(m))\n",
    "    #H = Array(Float64, m, m)\n",
    "        for j in 1:n\n",
    "            for i in 1:m\n",
    "                gradient[i] = gradient[i] + digamma(X[j,i] + α0[i]) - digamma(α0[i]) - digamma(sum(X[j, :]) + sum(α0)) + digamma(sum(α0))\n",
    "            end\n",
    "        end\n",
    "        # evaluate gradient (score)\n",
    "        \n",
    "        # approximated observed information matrix\n",
    "        for j in 1:n\n",
    "            c = c + trigamma(sum(X[j, :]) + sum(α0))\n",
    "        end\n",
    "        \n",
    "        c = c - n * trigamma(sum(α0))\n",
    "                \n",
    "        for i = 1:m\n",
    "            for j in 1:n   \n",
    "                D[i,i] = D[i,i] - trigamma(α0[i] + X[j,i]) \n",
    "            end\n",
    "            D[i, i] = D[i, i] + n * trigamma(α0[i]) \n",
    "        end\n",
    "        \n",
    "        if (1 + c * dot(Z, inv(D) * Z)) <= 0\n",
    "            c = -.95 * 1 / dot(ones(m), inv(D) * ones(m))\n",
    "            print(counter,\"\\n\")\n",
    "        counter = counter + 1\n",
    "        end\n",
    "        H = D + ones(m) * ones(m)' * c\n",
    "        \n",
    "        # line search loop\n",
    "        for lsiter in 1:10\n",
    "            s = (2.0)^(- 2 * lsiter + 2)\n",
    "            αtemp = α0 + inv(H) * gradient * s\n",
    "            logltemp = sum(dirmult_logpdf(X',αtemp))\n",
    "            if (logltemp > logl) & (minimum(αtemp) > 0)\n",
    "            print(\"hi\")\n",
    "                stepsize = s\n",
    "                break;\n",
    "            end\n",
    "        end\n",
    "    \n",
    "        # compute Newton's direction\n",
    "        \n",
    "        α0 = α0 + inv(H) * gradient * stepsize\n",
    "        logl = sum(dirmult_logpdf(X',α0))\n",
    "        if abs(logl - loglold) < (tolfun * (abs(loglold) + 1))\n",
    "            print(\"converged\")\n",
    "            break;\n",
    "        end\n",
    "        for i in 1:m\n",
    "            gradient[i] = 0\n",
    "            H[i, i] = 0\n",
    "            D[i, i] = 0\n",
    "        end\n",
    "end\n",
    "#print(α0)\n",
    "#print(sum(dirmult_logpdf(X', α0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mult_logpdf"
      ]
     },
     "execution_count": 1077,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mult_logpdf!(r::Vector, X::Matrix, p::Vector)\n",
    "    for j in 1:size(X, 2)\n",
    "        d = Multinomial(sum(X[:, j]), p)\n",
    "        r[j] = logpdf(d, X[j, :])\n",
    "    end\n",
    "    return r\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    dirmult_logpdf(X, α)\n",
    "    \n",
    "Compute the log-pdf of Dirichlet-multinomial distribution with parameter `α` \n",
    "at each data point in `X`. Each column of `X` is one data point.\n",
    "\"\"\"\n",
    "function mult_logpdf(X::Matrix, p::Vector)\n",
    "    r = zeros(size(X, 2))\n",
    "    dirmult_logpdf!(r, X, p)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "382-element Array{Float64,1}:\n",
       " -221.222\n",
       " -178.145\n",
       " -214.711\n",
       " -207.392\n",
       " -197.372\n",
       " -181.379\n",
       " -156.062\n",
       " -180.863\n",
       " -191.406\n",
       " -191.051\n",
       " -190.673\n",
       " -204.709\n",
       " -188.582\n",
       "    ⋮    \n",
       " -220.019\n",
       " -218.306\n",
       " -160.29 \n",
       " -188.843\n",
       " -203.066\n",
       " -186.775\n",
       " -211.097\n",
       " -190.906\n",
       " -178.746\n",
       " -233.919\n",
       " -182.894\n",
       " -191.807"
      ]
     },
     "execution_count": 1079,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = sum(X, 1) ./ sum(X)\n",
    "p = vec(p)\n",
    "d = Multinomial(sum(X[1, :]), vec(p))\n",
    "logpdf(d, X[1, :])\n",
    "mult_logpdf(X', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000244140625"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 1\n",
    "        for lsiter in 1:20\n",
    "            s = (2.0)^(- lsiter - 1)\n",
    "            αtemp = α0 + inv(H) * gradient * s\n",
    "            logltemp = sum(dirmult_logpdf(X',αtemp))\n",
    "            if (logltemp > (logl + s * dot(gradient, inv(H) * gradient))) & (minimum(αtemp) > 0)\n",
    "                stepsize = s\n",
    "                break;\n",
    "            end\n",
    "        end\n",
    "\n",
    "αtemp\n",
    "    stepsize\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-51735.148891419056"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dirmult_logpdf(X', α0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48-element Array{Float64,1}:\n",
       "  0.0374573\n",
       "  4.9944   \n",
       " 14.9002   \n",
       " 12.1676   \n",
       "  2.45644  \n",
       "  0.063539 \n",
       "  1.02392  \n",
       " 14.6018   \n",
       " 14.7624   \n",
       " 13.749    \n",
       " 11.9442   \n",
       "  0.545983 \n",
       "  4.16774  \n",
       "  ⋮        \n",
       "  0.735115 \n",
       " 14.8423   \n",
       " 11.8115   \n",
       " 11.7306   \n",
       " 15.2444   \n",
       "  2.5917   \n",
       "  0.0207704\n",
       "  5.0277   \n",
       " 15.3815   \n",
       " 15.0797   \n",
       "  5.82498  \n",
       "  0.194466 "
      ]
     },
     "execution_count": 1114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirmult_newton(X, α0 = ones(m))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.1",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
