{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000×10000 Array{Float64,2}:\n",
       " 0.0  2.0  2.0  1.0  1.0  1.0  0.0  2.0  …  0.0  2.0  2.0  2.0  1.0  1.0  1.0\n",
       " 1.0  2.0  1.0  2.0  0.0  1.0  1.0  2.0     2.0  2.0  2.0  0.0  2.0  1.0  0.0\n",
       " 1.0  2.0  0.0  1.0  0.0  2.0  0.0  2.0     1.0  2.0  2.0  2.0  1.0  1.0  0.0\n",
       " 2.0  2.0  1.0  2.0  2.0  1.0  0.0  1.0     0.0  0.0  1.0  1.0  1.0  1.0  1.0\n",
       " 2.0  1.0  2.0  1.0  1.0  2.0  1.0  0.0     1.0  2.0  0.0  0.0  1.0  1.0  2.0\n",
       " 0.0  2.0  2.0  0.0  2.0  1.0  2.0  1.0  …  0.0  1.0  0.0  1.0  1.0  2.0  2.0\n",
       " 0.0  1.0  0.0  0.0  1.0  2.0  1.0  1.0     2.0  2.0  1.0  1.0  2.0  2.0  0.0\n",
       " 1.0  2.0  1.0  0.0  2.0  1.0  2.0  1.0     2.0  1.0  1.0  2.0  0.0  1.0  1.0\n",
       " 1.0  1.0  2.0  2.0  1.0  2.0  2.0  2.0     2.0  1.0  1.0  0.0  0.0  1.0  0.0\n",
       " 0.0  2.0  1.0  1.0  0.0  1.0  0.0  2.0     2.0  0.0  2.0  2.0  0.0  2.0  0.0\n",
       " 2.0  0.0  0.0  1.0  2.0  2.0  1.0  0.0  …  0.0  0.0  1.0  0.0  1.0  0.0  0.0\n",
       " 2.0  2.0  2.0  1.0  1.0  1.0  2.0  2.0     2.0  0.0  1.0  2.0  0.0  1.0  0.0\n",
       " 0.0  2.0  0.0  2.0  2.0  0.0  1.0  0.0     0.0  0.0  0.0  2.0  2.0  2.0  0.0\n",
       " ⋮                        ⋮              ⋱            ⋮                      \n",
       " 0.0  1.0  2.0  1.0  1.0  1.0  2.0  2.0     0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
       " 0.0  0.0  1.0  2.0  0.0  0.0  0.0  1.0     0.0  2.0  0.0  1.0  2.0  1.0  1.0\n",
       " 2.0  1.0  1.0  1.0  2.0  0.0  0.0  1.0  …  1.0  0.0  2.0  2.0  2.0  1.0  1.0\n",
       " 2.0  2.0  1.0  2.0  1.0  1.0  1.0  0.0     1.0  1.0  1.0  1.0  0.0  2.0  0.0\n",
       " 0.0  2.0  2.0  0.0  0.0  0.0  0.0  0.0     0.0  1.0  1.0  1.0  1.0  0.0  2.0\n",
       " 0.0  0.0  1.0  0.0  1.0  1.0  1.0  1.0     1.0  0.0  1.0  2.0  2.0  0.0  1.0\n",
       " 1.0  0.0  0.0  0.0  0.0  0.0  2.0  2.0     0.0  2.0  0.0  0.0  0.0  1.0  1.0\n",
       " 0.0  2.0  2.0  1.0  0.0  1.0  0.0  2.0  …  0.0  1.0  2.0  2.0  1.0  2.0  2.0\n",
       " 1.0  0.0  0.0  1.0  2.0  1.0  1.0  1.0     0.0  2.0  1.0  2.0  1.0  2.0  2.0\n",
       " 1.0  0.0  2.0  0.0  2.0  2.0  1.0  0.0     1.0  0.0  0.0  2.0  2.0  1.0  1.0\n",
       " 0.0  1.0  1.0  0.0  2.0  2.0  1.0  1.0     0.0  0.0  1.0  1.0  0.0  1.0  2.0\n",
       " 1.0  0.0  0.0  1.0  0.0  2.0  1.0  1.0     1.0  1.0  0.0  1.0  1.0  2.0  0.0"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using BenchmarkTools\n",
    "srand(280) # seed\n",
    "X = rand(0.0:2.0, 1000, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition naive2"
     ]
    },
    {
     "data": {
      "text/plain": [
       "naive2 (generic function with 1 method)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Array{Float64, 2}) in module Main at In[180]:3 overwritten at In[259]:3.\n"
     ]
    }
   ],
   "source": [
    "function naive2(X::Matrix{Float64})\n",
    "    \n",
    "    n = size(X, 1)\n",
    "    m = size(X, 2)\n",
    "    A = repmat(sum(X, 2),1,n)\n",
    "    ematrix = Matrix{Float64}(n, n)\n",
    "    phi = Matrix{Float64}(n, n)\n",
    "    p = sum(X, 1) / (2.0 * n)\n",
    "    pnorm = sumabs2(p)\n",
    "    pnorm2 = sumabs2(1 - p)\n",
    "    ematrix = 1.0 / 4.0 .* (LowerTriangular(Base.LinAlg.BLAS.syr!('L', 4.0 * m, ones(n),\n",
    "                tril(Base.LinAlg.BLAS.syrk('L', 'N', 2.0, X)))) - \n",
    "                2.0 * LowerTriangular(A) - 2.0 * LowerTriangular(A'))\n",
    "    phi = (Matrix(ematrix) - pnorm - pnorm2) ./ (m - pnorm - pnorm2)\n",
    "    ematrix\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    n = size(X, 1)\n",
    "    m = size(X, 2)\n",
    "A = repmat(sum(X, 2),1,n)\n",
    "    ematrix = Matrix{Float64}(n, n)\n",
    "    phi = Matrix{Float64}(n, n)\n",
    "    p = sum(X, 1) / (2.0 * n)\n",
    "    pnorm = sumabs2(p)\n",
    "    pnorm2 = sumabs2(1 - p)\n",
    "pnorm\n",
    "onen = ones(n)\n",
    "onem = ones(m)\n",
    "temp = Matrix{Float64}(n, n)\n",
    "    taco = sum(X, 2)\n",
    "    for j = 1:n\n",
    "        for i = j:n\n",
    "           temp[i, j] = taco[i] + taco[j] \n",
    "        end\n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition kinship(Array{"
     ]
    },
    {
     "data": {
      "text/plain": [
       "kinship (generic function with 1 method)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Float64, 2}) in module Main at In[287]:3 overwritten at In[289]:3.\n"
     ]
    }
   ],
   "source": [
    "function kinship(X::Matrix{Float64})\n",
    "    \n",
    "    n = size(X, 1)\n",
    "    m = size(X, 2)\n",
    "    phi = Matrix{Float64}(n, n)\n",
    "    p = sum(X, 1) / (2.0 * n)\n",
    "    pnorm = sumabs2(p)\n",
    "    pnorm2 = sumabs2(1 - p)\n",
    "    taco = sum(X, 2)\n",
    "\n",
    "    phi = 1.0 / 4.0 * (Base.LinAlg.BLAS.syr!('L', 4.0 * m, ones(n),\n",
    "                Base.LinAlg.BLAS.syrk('L', 'N', 2.0, X)))\n",
    "    \n",
    "    for j = 1:n\n",
    "        for i = j:n\n",
    "            phi[i, j] = (phi[i, j] - 1.0 / 2.0 * (taco[i] + taco[j]) - pnorm - pnorm2) / (m - pnorm - pnorm2)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    for j = 2:n\n",
    "        for i = 1:j\n",
    "            phi[i, j] = phi[j, i]\n",
    "        end\n",
    "    end\n",
    "    phi\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  23.13 MiB\n",
       "  allocs estimate:  22\n",
       "  --------------\n",
       "  minimum time:     132.958 ms (0.28% GC)\n",
       "  median time:      143.285 ms (1.06% GC)\n",
       "  mean time:        144.458 ms (1.01% GC)\n",
       "  maximum time:     170.369 ms (0.89% GC)\n",
       "  --------------\n",
       "  samples:          35\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark kinship(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2\n",
    "\n",
    "0. Show the **Sherman-Morrison formula**\n",
    "$$\n",
    "\t(\\mathbf{A} + \\mathbf{u} \\mathbf{u}^T)^{-1} = \\mathbf{A}^{-1} - \\frac{1}{1 + \\mathbf{u}^T \\mathbf{A}^{-1} \\mathbf{u}} \\mathbf{A}^{-1} \\mathbf{u} \\mathbf{u}^T \\mathbf{A}^{-1},\n",
    "$$\n",
    "where $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ is nonsingular and $\\mathbf{u} \\in \\mathbb{R}^n$. This formula supplies the inverse of the symmetric, rank-one  perturbation of $\\mathbf{A}$.\n",
    "\n",
    "0. Show the **Woodbury formula**\n",
    "$$\n",
    "\t(\\mathbf{A} + \\mathbf{U} \\mathbf{V}^T)^{-1} = \\mathbf{A}^{-1} - \\mathbf{A}^{-1} \\mathbf{U} (\\mathbf{I}_m + \\mathbf{V}^T \\mathbf{A}^{-1} \\mathbf{U})^{-1} \\mathbf{V}^T \\mathbf{A}^{-1},\n",
    "$$\n",
    "where $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ is nonsingular, $\\mathbf{U}, \\mathbf{V} \\in \\mathbb{R}^{n \\times m}$, and $\\mathbf{I}_m$ is the $m \\times m$ identity matrix. In many applications $m$ is much smaller than $n$. Woodbury formula generalizes Sherman-Morrison and is valuable because the smaller matrix $\\mathbf{I}_m + \\mathbf{V}^T \\mathbf{A}^{-1} \\mathbf{U}$ is cheaper to invert than the larger matrix $\\mathbf{A} + \\mathbf{U} \\mathbf{V}^T$.\n",
    "\n",
    "0. Show the **binomial inversion formula**\n",
    "$$\n",
    "\t(\\mathbf{A} + \\mathbf{U} \\mathbf{B} \\mathbf{V}^T)^{-1} = \\mathbf{A}^{-1} - \\mathbf{A}^{-1} \\mathbf{U} (\\mathbf{B}^{-1} + \\mathbf{V}^T \\mathbf{A}^{-1} \\mathbf{U})^{-1} \\mathbf{V}^T \\mathbf{A}^{-1},\n",
    "$$\n",
    "where $\\mathbf{A}$ and $\\mathbf{B}$ are nonsingular.\n",
    "\n",
    "0. Show the identity\n",
    "$$\n",
    "\t\\text{det}(\\mathbf{A} + \\mathbf{U} \\mathbf{V}^T) = \\text{det}(\\mathbf{A}) \\text{det}(\\mathbf{I}_m + \\mathbf{V}^T \\mathbf{A}^{-1} \\mathbf{U}).\n",
    "$$\n",
    "This formula is useful for evaluating the density of a multivariate normal with covariance matrix $\\mathbf{A} + \\mathbf{U} \\mathbf{V}^T$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Assume $(\\mathbf{A} + \\mathbf{uu}^{T})$ is invertible. I will show the Sherman-Morrison formula satisfies the properties of an inverse.\n",
    "$$\n",
    "\\begin{align}\n",
    "(\\mathbf{A} + \\mathbf{uu}^{T})\\bigg(\\mathbf{A}^{-1} - \\frac{1}{1+\\mathbf{u}^{T}\\mathbf{A}^{-1}\\mathbf{u}}\\mathbf{A}^{-1}\\mathbf{uu}^{T}\\mathbf{A}^{-1}\\bigg) &=\\mathbf{I} - \\frac{\\mathbf{uu}^{T}\\mathbf{A}^{-1}}{1+\\mathbf{u}^{T}\\mathbf{A}^{-1}\\mathbf{u}} + \\mathbf{uu}^{T}A^{-1}\\mathbf{} -\\frac{\\mathbf{uu}^{T}\\mathbf{A}^{-1}\\mathbf{uu}^{T}\\mathbf{A}^{-1}}{1 + \\mathbf{u}^{T}\\mathbf{A}^{-1}\\mathbf{u}}\\\\\n",
    "&=\\mathbf{I} - \\frac{\\mathbf{uu}^{T}\\mathbf{A}^{-1}}{1+\\mathbf{u}^{T}\\mathbf{A}^{-1}\\mathbf{u}} + \\frac{\\mathbf{uu}^{T}A^{-1}+\\mathbf{u}^{T}\\mathbf{A}^{-1}\\mathbf{u}\\mathbf{uu}^{T}\\mathbf{A}^{-1}}{1+\\mathbf{u}^{T}\\mathbf{A}^{-1}\\mathbf{u}} -\\frac{\\mathbf{uu}^{T}\\mathbf{A}^{-1}\\mathbf{uu}^{T}\\mathbf{A}^{-1}}{1 + \\mathbf{u}^{T}\\mathbf{A}^{-1}\\mathbf{u}}\\\\\n",
    "&=\\mathbf{I} + \\frac{\\mathbf{uu}^{T}\\mathbf{A}^{-1}\\mathbf{uu}^{T}\\mathbf{A}^{-1}}{1+\\mathbf{u}^{T}\\mathbf{A}^{-1}\\mathbf{u}}-\\frac{\\mathbf{uu}^{T}\\mathbf{A}^{-1}\\mathbf{uu}^{T}\\mathbf{A}^{-1}}{1 + \\mathbf{u}^{T}\\mathbf{A}^{-1}\\mathbf{u}}\\\\\n",
    "&=\\mathbf{I}\n",
    "\\end{align}\n",
    "$$\n",
    "This shows the Sherman-Morrison formula is a right-inverse. I need to check it's a left-inverse as well.\n",
    "$$\n",
    "\\begin{align}\n",
    "\\bigg(\\mathbf{A}^{-1} - \\frac{1}{1+\\mathbf{u}^{T}\\mathbf{A}^{-1}\\mathbf{u}}\\mathbf{A}^{-1}\\mathbf{uu}^{T}\\mathbf{A}^{-1}\\bigg) (\\mathbf{A} + \\mathbf{uu}^{T})&=\\mathbf{I} + \\mathbf{A}^{-1}\\mathbf{uu}^{T} - \\frac{\\mathbf{A}^{-1}\\mathbf{uu}^{T}}{1+\\mathbf{u}^{T}\\mathbf{A}^{-1}\\mathbf{u}} - \\frac{\\mathbf{A}^{-1}\\mathbf{uu}^{T}\\mathbf{A}^{-1}\\mathbf{uu}^{T}}{1+\\mathbf{u}^{T}\\mathbf{A}^{-1}\\mathbf{u}}\\\\\n",
    "&=\\mathbf{I} + \\frac{\\mathbf{A}^{-1}\\mathbf{uu}^{T}+\\mathbf{u}^{T}\\mathbf{A}^{-1}\\mathbf{u}\\mathbf{A}^{-1}\\mathbf{uu}^{T}-\\mathbf{A}^{-1}\\mathbf{uu}^{T}-\\mathbf{A}^{-1}\\mathbf{uu}^{T}\\mathbf{A}^{-1}\\mathbf{uu}^{T}}{1+\\mathbf{u}^{T}\\mathbf{A}^{-1}\\mathbf{u}}\\\\\n",
    "&= \\mathbf{I}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    " By definition of inverse,  $(\\mathbf{A} + \\mathbf{uu}^{T})^{-1}=\\mathbf{A}^{-1} - \\displaystyle\\frac{1}{1 + \\mathbf{u}^T \\mathbf{A}^{-1} \\mathbf{u}} \\mathbf{A}^{-1} \\mathbf{u} \\mathbf{u}^T \\mathbf{A}^{-1}$\n",
    " \n",
    "2. In a similar manner,\n",
    "$$\n",
    "\\begin{align}\n",
    "(\\mathbf{A} + \\mathbf{UV}^{T})(\\mathbf{A}^{-1} - \\mathbf{A}^{-1} \\mathbf{U} (\\mathbf{I}_m + \\mathbf{V}^T \\mathbf{A}^{-1} \\mathbf{U})^{-1} \\mathbf{V}^T \\mathbf{A}^{-1})&=\\mathbf{I_n} + \\mathbf{UV}^{T}\\mathbf{A}^{-1}-\\mathbf{U}(\\mathbf{I_m}\n",
    "+\\mathbf{V}^{T}\\mathbf{A}^{-1}\\mathbf{U})^{-1}\\mathbf{V}^{T}\\mathbf{A}^{-1} - \\mathbf{UV}^{T}\\mathbf{A}^{-1}\\mathbf{U}(\\mathbf{I_m}+\\mathbf{V}^{T}\\mathbf{A}^{-1}\\mathbf{U})\\mathbf{V}^{T}\\mathbf{A}^{-1}\\\\\n",
    "&=\\mathbf{I_n}+\\mathbf{UV}^{T}\\mathbf{A}^{-1}-(\\mathbf{U}+\\mathbf{UV}^{T}\\mathbf{A}^{-1}\\mathbf{U})(\\mathbf{I_m}+\\mathbf{V}^{T}\\mathbf{A}^{-1}\\mathbf{U})^{-1}\\mathbf{V}^{T}\\mathbf{A}^{-1}\\\\\n",
    "&=\\mathbf{I_n} + \\mathbf{UV}^{T}\\mathbf{A}^{-1}-\\mathbf{U}(\\mathbf{I_m}+\\mathbf{V}^{T}\\mathbf{A}^{-1}\\mathbf{U})(\\mathbf{I_m}+\\mathbf{V}^{T}\\mathbf{A}^{-1}\\mathbf{U})^{-1}\\mathbf{V}^{T}\\mathbf{A}^{-1}\\\\\n",
    "&=\\mathbf{I_n}+\\mathbf{UV}^{T}\\mathbf{A}^{-1}-\\mathbf{U}\\mathbf{V}^{T}\\mathbf{A}^{-1}\\\\\n",
    "&=\\mathbf{I_n}\n",
    "\\end{align}\n",
    "$$\n",
    " \n",
    " This shows the Woodbury formula is a right inverse for $\\mathbf{A} + \\mathbf{UV}^{T}$. To show it's a left inverse:\n",
    "$$\n",
    "\\begin{align}\n",
    "(\\mathbf{A}^{-1} - \\mathbf{A}^{-1} \\mathbf{U} (\\mathbf{I}_m + \\mathbf{V}^T \\mathbf{A}^{-1} \\mathbf{U})^{-1} \\mathbf{V}^T \\mathbf{A}^{-1})(\\mathbf{A} + \\mathbf{UV}^{T})&= \\mathbf{I_n} + \\mathbf{A}^{-1}\\mathbf{UV}^{T}-\\mathbf{A}^{-1}\\mathbf{U}(\\mathbf{I_m}+\\mathbf{V}^{T}\\mathbf{A}^{-1}\\mathbf{U})^{-1}\\mathbf{V}^{T}-\\mathbf{A}^{-1}\\mathbf{U}(\\mathbf{I_m}+\\mathbf{V}^{T}\\mathbf{A}^{-1}\\mathbf{U})^{-1}\\mathbf{V}^{T}\\mathbf{A}^{-1}\\mathbf{UV}^{T}\\\\\n",
    "&=\\mathbf{I_n}+\\mathbf{A}^{-1}\\mathbf{UV}^{T}-\\mathbf{A}^{-1}\\mathbf{U}(\\mathbf{I_m}+\\mathbf{V}^{T}\\mathbf{A}^{-1}\\mathbf{U})^{-1}(\\mathbf{V}^{T}+\\mathbf{V}^{T}\\mathbf{A}^{-1}\\mathbf{UV}^{T})\\\\\n",
    "&=\\mathbf{I_n}+\\mathbf{A}^{-1}\\mathbf{UV}^{T}-\\mathbf{A}^{-1}\\mathbf{U}(\\mathbf{I_m}+\\mathbf{V}^{T}\\mathbf{A}^{-1}\\mathbf{U})^{-1}(\\mathbf{I_m}+\\mathbf{V}^{T}\\mathbf{A}^{-1}\\mathbf{U})\\mathbf{V}^{T}\\\\\n",
    "&=\\mathbf{I_n}+\\mathbf{A}^{-1}\\mathbf{UV}^{T}-\\mathbf{A}^{-1}\\mathbf{UV}^{T}\\\\\n",
    "&=\\mathbf{I_n}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    " By definition of inverse, $(\\mathbf{A} + \\mathbf{UV}^{T})^{-1}=(\\mathbf{A}^{-1} - \\mathbf{A}^{-1} \\mathbf{U} (\\mathbf{I}_m + \\mathbf{V}^T \\mathbf{A}^{-1} \\mathbf{U})^{-1} \\mathbf{V}^T \\mathbf{A}^{-1})$\n",
    " \n",
    "3. Continuing, \n",
    "$$\n",
    "\\begin{align}\n",
    "(\\mathbf{A}+\\mathbf{UBV}^{T})(\\mathbf{A}^{-1} - \\mathbf{A}^{-1} \\mathbf{U} (\\mathbf{B}^{-1} + \\mathbf{V}^T \\mathbf{A}^{-1} \\mathbf{U})^{-1} \\mathbf{V}^T \\mathbf{A}^{-1})&= \\mathbf{I_n}-\\mathbf{U}(\\mathbf{B}^{-1}+\\mathbf{V}^{T}\\mathbf{A}^{-1}\\mathbf{U})^{-1}\\mathbf{V}^{T}\\mathbf{A}^{-1}+\\mathbf{UBV}^{T}\\mathbf{A}^{-1}-\\mathbf{UBV}^{T}\\mathbf{A}^{-1}\\mathbf{U}(\\mathbf{B}^{-1}+\\mathbf{V}^{T}\\mathbf{A}^{-1}\\mathbf{U})^{-1}\\mathbf{V}^{T}\\mathbf{A}^{-1}\\\\\n",
    "&=\\mathbf{I_n}+\\mathbf{UBV}^{T}\\mathbf{A}^{-1}-(\\mathbf{U}+\\mathbf{UBV}^{T}\\mathbf{A}^{-1}\\mathbf{U})(\\mathbf{B}^{-1}+\\mathbf{V}^{T}\\mathbf{A}^{-1}\\mathbf{U})^{-1}\\mathbf{V}^{T}\\mathbf{A}^{-1}\\\\\n",
    "&=\\mathbf{I_n}+\\mathbf{UBV}^{T}\\mathbf{A}^{-1}-\\mathbf{UB}(\\mathbf{B}^{-1}+\\mathbf{V}^{T}\\mathbf{A}^{-1}\\mathbf{U})(\\mathbf{B}^{-1}+\\mathbf{V}^{T}\\mathbf{A}^{-1}\\mathbf{U})^{-1}\\mathbf{V}^{T}\\mathbf{A}^{-1}\\\\\n",
    "&=\\mathbf{I_n}+\\mathbf{UBV}^{T}\\mathbf{A}^{-1}-\\mathbf{UBV}^{T}\\mathbf{A}^{-1}\\\\\n",
    "&=\\mathbf{I_n}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    " Left inverse:\n",
    "$$\n",
    "\\begin{align}\n",
    "(\\mathbf{A}^{-1} - \\mathbf{A}^{-1} \\mathbf{U} (\\mathbf{B}^{-1} + \\mathbf{V}^T \\mathbf{A}^{-1} \\mathbf{U})^{-1} \\mathbf{V}^T \\mathbf{A}^{-1})(\\mathbf{A}+\\mathbf{UBV}^{T})&=\\mathbf{I_n} + \\mathbf{A}^{-1}\\mathbf{UBV}^{T}-\\mathbf{A}^{-1}\\mathbf{U}(\\mathbf{B}^{-1}+\\mathbf{V}^{T}\\mathbf{A}^{-1}\\mathbf{U})^{-1}-\\mathbf{A}^{-1}\\mathbf{U}(\\mathbf{B}^{-1}+\\mathbf{V}^{T}\\mathbf{A}^{-1}\\mathbf{U})^{-1}\\mathbf{V}^{T}\\mathbf{A}^{-1}\\mathbf{UBV}^{T}\\\\\n",
    "&=\\mathbf{I_n}+\\mathbf{A}^{-1}\\mathbf{UBV}^{T}-\\mathbf{A}^{-1}\\mathbf{U}(\\mathbf{B}^{-1}+\\mathbf{V}^{T}\\mathbf{A}^{-1}\\mathbf{U})^{-1}(\\mathbf{V}^{T}+\\mathbf{V}^{T}\\mathbf{A}^{-1}\\mathbf{UBV}^{T})\\\\\n",
    "&=\\mathbf{I_n}+\\mathbf{A}^{-1}\\mathbf{UBV}^{T}-\\mathbf{A}^{-1}\\mathbf{U}(\\mathbf{B}^{-1}+\\mathbf{V}^{T}\\mathbf{A}^{-1}\\mathbf{U})^{-1}(\\mathbf{B}^{-1}+\\mathbf{V}^{T}\\mathbf{A}^{-1}\\mathbf{U})\\mathbf{BV}^{T}\\\\\n",
    "&=\\mathbf{I_n}+\\mathbf{A}^{-1}\\mathbf{UBV}^{T}-\\mathbf{A}^{-1}\\mathbf{UBV}^{T}\\\\\n",
    "&=\\mathbf{I_n}\n",
    "\\end{align}\n",
    "$$\n",
    " This shows $(\\mathbf{A}+\\mathbf{UBV}^{T})^{-1} = \\mathbf{A}^{-1} - \\mathbf{A}^{-1} \\mathbf{U} (\\mathbf{B}^{-1} + \\mathbf{V}^T \\mathbf{A}^{-1} \\mathbf{U})^{-1} \\mathbf{V}^T \\mathbf{A}^{-1}$\n",
    " \n",
    "4. Observate that\n",
    " $$\n",
    "\\begin{align}\n",
    "\\begin{pmatrix}\\mathbf{I_n} & \\mathbf{U}\\\\\\mathbf{0_{m\\times n}} & \\mathbf{I_m}+\\mathbf{V}^{T}\\mathbf{U}\\end{pmatrix} = \\begin{pmatrix}\\mathbf{I_n} & \\mathbf{0_{n\\times m}}\\\\\\mathbf{V}^{T} & \\mathbf{I_m}\\end{pmatrix}\\begin{pmatrix}\\mathbf{I_n}+\\mathbf{U}\\mathbf{V}^{T} & \\mathbf{U}\\\\\\mathbf{0_{m\\times n}} & \\mathbf{I_m}\\end{pmatrix}\\begin{pmatrix}\\mathbf{I_n} & \\mathbf{0_{n\\times m}}\\\\-\\mathbf{V}^{T} & \\mathbf{I_m}\\end{pmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    " The determinant of a product is the product of determinants. Thus, $\\text{det}(\\mathbf{I_n} + \\mathbf{UV}^{T}) = \\text{det}(\\mathbf{I_m}+\\mathbf{V}^{T}\\mathbf{U})$\n",
    " \n",
    " Therefore\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{det}(\\mathbf{A}+\\mathbf{U}\\mathbf{V}^{T}) &=\\text{det}(\\mathbf{A}+\\mathbf{A}\\mathbf{A}^{-1}\\mathbf{UV}^{T})\\\\\n",
    "&=\\text{det}(\\mathbf{A})\\text{det}(\\mathbf{I_n}+\\mathbf{A}^{-1}\\mathbf{UV}^{T})\\\\\n",
    "&=\\text{det}(\\mathbf{A})\\text{det}(\\mathbf{I_m}+\\mathbf{V}^{T}\\mathbf{A}^{-1}\\mathbf{U})\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3\n",
    "\n",
    "Consider a mixed effects model\n",
    "$$\n",
    "\ty_i = \\mathbf{x}_i^T \\beta + \\mathbf{z}_i^T \\gamma + \\epsilon_i, \\quad i=1,\\ldots,n,\n",
    "$$\n",
    "where $\\epsilon_i$ are independent normal errors $N(0,\\sigma_0^2)$, $\\beta \\in \\mathbb{R}^p$ are fixed effects, and $\\gamma \\in \\mathbb{R}^q$ are random effects assumed to be $N(\\mathbf{0}_q, \\sigma_1^2 \\mathbf{I}_q$) independent of $\\epsilon_i$. \n",
    "\n",
    "0. Show that \n",
    "$$\n",
    "    \\mathbf{y} \\sim N \\left( \\mathbf{X} \\beta, \\sigma_0^2 \\mathbf{I}_n + \\sigma_1^2 \\mathbf{Z} \\mathbf{Z}^T \\right),\n",
    "$$\n",
    "where $\\mathbf{y} \\in \\mathbb{R}^n$, $\\mathbf{X} \\in \\mathbb{R}^{n \\times p}$, and $\\mathbf{Z} \\in \\mathbb{R}^{n \\times q}$. \n",
    "\n",
    "0. Write a function, with interface \n",
    "    ```julia\n",
    "    logpdf_mvn(y, Z, σ0, σ1),\n",
    "    ```\n",
    "that evaluates the log-density of a multivariate normal with mean $\\mathbf{0}$ and covariance $\\sigma_0^2 \\mathbf{I} + \\sigma_1^2 \\mathbf{Z} \\mathbf{Z}^T$ at $\\mathbf{y}$. Make your code efficient in the $n \\gg q$ case. \n",
    "\n",
    "0. Compare your result (both accuracy and timing) to the [Distributions.jl](http://distributionsjl.readthedocs.io/en/latest/multivariate.html#multivariate-normal-distribution) package using following data.  \n",
    "    ```julia\n",
    "    using BenchmarkTools, Distributions\n",
    "\n",
    "    srand(280)\n",
    "    n, q = 2000, 10\n",
    "    Z = randn(n, q)\n",
    "    σ0, σ1 = 0.5, 2.0\n",
    "    Σ = σ1^2 * Z * Z.' + σ0^2 * I\n",
    "    mvn = MvNormal(Σ) # MVN(0, Σ)\n",
    "    y = rand(mvn) # generate one instance from MNV(0, Σ)\n",
    "\n",
    "    # check you answer matches that from Distributions.jl\n",
    "    @show logpdf_mvn(y, Z, σ0, σ1)\n",
    "    @show logpdf(mvn, y)\n",
    "\n",
    "    # benchmark\n",
    "    @benchmark logpdf_mvn(y, Z, σ0, σ1)\n",
    "    @benchmark logpdf(mvn, y)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. From the problem formulation, $\\mathbf{Z}\\gamma \\sim N_n(0, \\mathbf{Z}\\sigma^2_1\\mathbf{Z}^{T})$ and $\\varepsilon \\sim N_n(0,\\sigma^2_0\\mathbf{I_n})$ with $\\mathbf{Z}\\gamma$ independent of $\\varepsilon$\n",
    "\n",
    " Let $\\tilde{\\varepsilon} = \\mathbf{Z}\\gamma + \\varepsilon$. This is the sum of two independent multivariate normal variables, so $\\tilde{\\varepsilon} \\sim N_n(0, \\sigma^2_0\\mathbf{I_n} + \\sigma^2_1\\mathbf{Z}\\mathbf{Z}^{T})$\n",
    " \n",
    " Therefore $\\mathbf{y} = \\mathbf{X}\\beta + \\tilde{\\varepsilon} \\sim N(\\mathbf{X}\\beta, \\sigma^2_0\\mathbf{I_n} + \\sigma^2_1\\mathbf{Z}\\mathbf{Z}^{T})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Question 3, part 2\n",
    "\n",
    "using BenchmarkTools, Distributions\n",
    "\n",
    "srand(280)\n",
    "n, q = 2000, 10\n",
    "Z = randn(n, q)\n",
    "σ0, σ1 = 0.5, 2.0\n",
    "Σ = σ1^2 * Z * Z.' + σ0^2 * I\n",
    "mvn = MvNormal(Σ) # MVN(0, Σ)\n",
    "y = rand(mvn); # generate one instance from MNV(0, Σ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition "
     ]
    },
    {
     "data": {
      "text/plain": [
       "logpdf_mvn (generic function with 1 method)"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logpdf_mvn(Array{Float64, 1}, Array{Float64, 2}, Float64, Float64) in module Main at In[410]:2 overwritten at In[413]:2.\n"
     ]
    }
   ],
   "source": [
    "function logpdf_mvn(y::Array{Float64,1}, Z::Array{Float64,2}, σ0::Float64, σ1::Float64)\n",
    "    k = length(y)\n",
    "    \n",
    "    # Using matrix determinant lemma\n",
    "    decomp1 = (4000 * log(σ0) + logdet(I + σ1^2/σ0^2 * Z' * Z))\n",
    "    \n",
    "    # Using Woodbury formula\n",
    "    Σchol = cholfact(I + σ1^2 / σ0^2 * Z' * Z)\n",
    "    decomp2 = (1/σ0^2 * sumabs2(y)-σ1^2 / σ0^4 * sumabs2(Σchol[:L] \\ Z' * y))\n",
    "    \n",
    "    # Multivariate normal pdf\n",
    "    - (k//2) * log(2π) - (1//2) * decomp1 - (1//2) * decomp2\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logpdf_mvn(y,Z,σ0,σ1) = -1571.5736734653365\n",
      "logpdf(mvn,y) = -1571.5736734654183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1571.5736734654183"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show logpdf_mvn(y, Z, σ0, σ1)\n",
    "@show logpdf(mvn, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  944.81 KiB\n",
       "  allocs estimate:  36\n",
       "  --------------\n",
       "  minimum time:     246.004 μs (0.00% GC)\n",
       "  median time:      359.832 μs (0.00% GC)\n",
       "  mean time:        405.162 μs (15.85% GC)\n",
       "  maximum time:     3.007 ms (53.77% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark logpdf_mvn(y, Z, σ0, σ1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  15.78 KiB\n",
       "  allocs estimate:  3\n",
       "  --------------\n",
       "  minimum time:     5.842 ms (0.00% GC)\n",
       "  median time:      5.905 ms (0.00% GC)\n",
       "  mean time:        6.029 ms (0.00% GC)\n",
       "  maximum time:     8.360 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          825\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark logpdf(mvn, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3.3\n",
    "\n",
    "I exploited the special structure of the covariance matrix by using the matrix determinant lemma and Woodbury formula. The timing of my function is 14 times faster on average than the <code>logpdf</code> function. However, my function requires more overhead because I'm not passing a simple multivariate normal density to be evaluated as in the Distributions package. The evaluated densites are equal up to the ninth decimal point. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.1",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
